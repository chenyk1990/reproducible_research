%\documentclass[manuscript]{geophysics}
%\usepackage{amsmath}
\DeclareRobustCommand{\dlo}[1]{}
\DeclareRobustCommand{\wen}[1]{#1}
%\usepackage{amsmath}
%\usepackage{cite}
%\usepackage{inputenc}
\newcommand{\n}[1]{{\color{black}{#1}}}
%\usepackage{ifthen}
%\usepackage{seg}
%\usepackage{color}
%\usepackage{graphicx}
%\usepackage{graphicx} % needed for \includegraphics
%\usepackage{wrapfig} 
%%\usepackage{indentfirst}
%\usepackage{subfig}
%\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

%\begin{document}

\title{Robust damped rank-reduction method for simultaneous denoising and reconstruction of 5D seismic data}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\author{Yapo Abol{\'e} Serge Innocent Obou{\'e}\footnotemark[1], Wei Chen\footnotemark[2], Hang Wang\footnotemark[1] and Yangkang Chen\footnotemark[1]}

\ms{GEO-2020} %\ms{GJI-2019}

\address{\footnotemark[1]\quad Zhejiang University\\
	School of Earth Sciences\\
	Hangzhou, Zhejiang, China\\
	obouesonofgod1@gmail.com \& 18328504171@163.com \& chenyk2016@gmail.com\\
	\footnotemark[2]\quad Yangtze University\\
	Key Laboratory of Exploration Technology for Oil and Gas Resources of Ministry of Education\\
	Wuhan, Hubei, China\\
	chenwei2014@yangtzeu.edu.cn
	
Corresponding Author: Yangkang Chen (chenyk2016@gmail.com)
}

\lefthead{Obou{\'e} et al.}
\righthead{RDRR}

\maketitle


%\begin{center}
%	\huge{\textbf{Robust damped rank-reduction method for simultaneous denoising and reconstruction of 5-D seismic data}} 
%\end{center}

%\renewcommand{\thefootnote}{\fnsymbol{footnote}}

%\author{Yapo Abol{\'e} Serge Innocent Obou{\'e} \footnotemark[1], Wei Chen\footnotemark[2], Hang Wang\footnotemark[1] and Yangkang Chen\footnotemark[1]}

%\ms{GEO-2020} %\ms{GJI-2019}

%\address{\footnotemark[1]\quad Zhejiang University\\
%	School of Earth Sciences\\
%	Hangzhou, Zhejiang, China\\
%	obouesonofgod1@gmail.com \& 18328504171@163.com \& chenyk2016@gmail.com\\
%	\footnotemark[2]\quad Yangtze University\\
%	Key Laboratory of Exploration Technology for Oil and Gas Resources of Ministry of Education\\
%	Wuhan, Hubei, China\\
%	chenwei2014@yangtzeu.edu.cn
	
%Corresponding Author: Yangkang Chen (chenyk2016@gmail.com)
%}

%\lefthead{Obou{\'e} et al.}
%\righthead{RDRR}


\begin{abstract}

We have developed a new method for simultaneous denoising and reconstruction of 5D seismic data corrupted by random noise and missing traces. Several algorithms have been developed for seismic data restoration based on rank-reduction (RR) methods. More recently, a damping operator has been introduced into the conventional truncated singular-value decomposition (TSVD) formula to further remove residual noise, the presence of which disturbs the quality of the seismic results. Despite the success of the damped RR (DRR) method when the observed data have an extremely low signal-to-noise ratio (S/N), random noise is still a limiting factor for obtaining a perfect quality of the result. Therefore, how to accurately solve the simultaneous denoising and reconstruction problem with high fidelity is still challenging. We assume that introducing only the damping operator into the TSVD formula is not enough to remove the random noise and restore the useful signal well. By combining the soft thresholding (ST) operator and the moving-average (MA) filter, we have developed a new operator, which we call the STMA operator. Then, by introducing the STMA operator into the DRR framework, we have developed a new algorithm known as the robust DRR method, which aims at mixing the advantages of the STMA operator and the damping operator. The STMA operator is applied to the Hankel matrix after
damped TSVD to better remove residual noise. Examples of our approach on synthetic and field 5D seismic data demonstrate the better performance in terms of the visual examination and numerical test compared with the DRR approach. Our method aims at producing an effective low-rank filter and, thus, can perfectly enhance the S/N of the simultaneously denoised and reconstructed results with higher accuracy.
\end{abstract}

\section{Introduction}

   \dlo{In seismology exploration}\wen{In exploration seismology}, one of the main concerns is \dlo{to obtain}\wen{obtaining} a sufficient amount of data to draw meaningful conclusions. To achieve this, the data acquisition process must obey the Nyquist/Shannon sampling theorem to accurately restore the seismic data and, thus, provide an accurate image of the subsurface \citep{cao2011review,wang2013data}. However, because of physical and/or economic difficulties, seismic data are generally sub-sampled either sparsely or irregularly in one or more spatial directions. Such \dlo{reasons negatively influence}\wen{acquisition choices adversely affect} the Nyquist/Shannon sampling theorem \citep{chiu2014multidimensional}. Noisy and incomplete data are the direct consequences of the limitations in the acquisition process. Therefore, it is imperative that such data lacking much useful information is restored suitably. Otherwise, it may \wen{negatively} affect \dlo{seriously}fundamental processing steps\dlo{fundamental processing steps seriously}, \dlo{for instance}\wen{e.g.,} multiple attenuation, amplitude versus offset analysis, migration imaging filtering \citep{adamo20143d,lopez2015closed}. Restoration of noisy and missing traces becomes therefore unavoidable in the seismic data processing chain \citep{shuwei2016cs,yangkang2019nc}. 

To overcome data acquisition issues, several approaches have been proposed over the years. Among these approaches, we discern a wide and popular group of methods in geophysics, which uses the prediction\wen{-}based approach. They are able to handle aliased events using nonaliased low-frequency components of data to restore the missing traces. This category is highly competitive for the interpolation of aliased data \citep{spitz1991seismic,crawley1999interpolation,porsani1999seismic}.
\dlo{On another hand}\wen{On the other hand}, we note the group of approaches known as wave equation method\wen{s} \citep{ronen1987wave}. \dlo{These approaches focused}\wen{Those approaches relying} on the main information provided by the subsurface parameters such as the velocity distribution, are more often computationally expensive \citep{canning1998reducing,fomel2003seismic}. \dlo{Besides}\wen{In addition to} these methods, there is a group of sparsity-promoting transforms that can be understood \dlo{first}as an analytical transform. It has a fixed basis that uses the well-known techniques: for instance, Fourier and Radon transforms \citep{kabir1995restoration,abma20063d}, curvelet\dlo{and sparse wavelet} transforms \citep{candes20061}, \wen{and} seislet \dlo{and shearlet}transform \citep{fomel2010seislet}. Then, as a well-known approach, learning-based \citep{cai2014data,amir2017geo} methods are also widely used. 

Seismic data are generally considered as low-rank structures. Unfortunately, missing values, unrecorded data and/or noise\dlo{s} may extend the rank of seismic matrix or tensor \citep{chen2016simultaneous}. This basic assumption has favored the implementation of methods based on low-rank \wen{approximation} for the past years. Using truncated singular value decomposition (TSVD), which constitutes an essential tool of low-rank approaches, we can overcome the negative effects that augment the rank of seismic data. This wide category of the method can be referred to as multichannel singular spectrum analysis (MSSA)\wen{,} which \dlo{are}\wen{is} also known as Cadzow filtering. MSSA usually starts by including all the seismic data components into a matrix called Hankel or Toeplitz, and then, a rank\wen{-}reduction (RR) algorithm is used to restore the \dlo{mains}\wen{main} features of the data \citep{chen2016open,chen2016simultaneous,huang2016damped,huang2017double,zhang2017hybrid}. However, we have techniques based on multi-linear arrays decomposition. In this sub-group, seismic data \old{is}\wen{are} regarded as a tensor \citep{kreimer2012tensor,gao2015parallel}. The method operates directly on the seismic tensor rather than embedding the components into a multilevel Hankel or Toeplitz matrix.

For a long time, the low-rank method has been broadly applied for noise removal \citep{freire1988application,Trickett2008Cadzow,sacchi2009fx,trickett2009prestack}. More recently, it was successfully used for seismic data interpolation  \citep{oropeza2011simultaneous,chiu2014multidimensional,gan2015dealiased,huang2016damped,chen2016open,chen2016simultaneous,zhang2017hybrid,yangkang2020odrr}. Given the fact that low-rank matrix completion (MC) is based on \dlo{rank-reduction approach}\wen{low-rank} assumption, we can, therefore, bring it closer to some methods like compressed sensing (CS) \citep{candes2009exact}. \dlo{Focused}\wen{Focusing} on this idea, \citet{recht2010guaranteed} established a connection between MC and CS. Based on low-frequency elements to recover seismic data on regular grids, \citet{naghizadeh2012multidimensional} \dlo{suggested}\wen{suggest} using the theory developed by \citet{spitz1991seismic}. Indeed, \dlo{approaches like MSSA-based}\wen{MSSA-based approaches} are not effective to interpolate regularly sampled data. 
%By constructing a so-called "texture-patch mapping", \citet{yang2012seismic} rearranged first the seismic data into a texture-patch matrix that is of low-rank and then, used MC algorithms to solve the nuclear-norm minimization. Compared with the Hankel matrix-based methods, the direct MC algorithm is much faster and can deal well with the higher-scale problem \citep{yang2012seismic}.
\citet{kumar2012fast} \dlo{used}\wen{use} a matrix factorization with max-norm (MFMN) \citep{lee2010practical} to solve the MC optimization problem. Singular-value decomposition (SVD)-based algorithms suffer enough from running time. Using the MFMN, one can efficiently reduce the computation cost.
%which is the same as the method used in \citet{yang2012seismic}
Because seismic reconstruction issues are usually high-dimensional \citep{liu2004minimum,xu2010antileakage}, it is necessary to set problems where the irregularity of the sampling is in the two midpoint and offset coordinates. In this context, 5D seismic denoising and/or reconstruction appears and focuses on all spatial components of data. This particularity makes it more usual in recent years. Compared to 2D and 3D reconstruction\wen{s}, such data restoration is a helpful tool to enhance reconstruction performance \citep{gao2015parallel}.
Research area such as simultaneous denoising and reconstruction of seismic data \citep{oropeza2011simultaneous,chen2016simultaneous,zhang2017hybrid} has arisen to overcome high-dimensional seismic data interpolation problem, which usually suffers from random noise. In this perspective, \citet{oropeza2011simultaneous} introduce the MSSA approach based on a low-rank assumption into seismic data restoration. 
The \dlo{solution} method first introduces the physical elements of seismic data into the block Hankel matrix and then uses a rapid strategy like randomized SVD (RSVD) to efficiently recover the signal. Although the affinities between a key parameter called alpha and signal-to-noise ratio (S/N) are not well understood from this approach, it accomplished its task with great success. In the same context, \citet{kreimer2012tensor} \old{considered}\wen{consider} the 5D seismic volume as a tensor and then used the high-order SVD (HOSVD) to reduce the rank of the tensor to restore the seismic data. Computation time is still a basic concern for most approaches based on low-rank assumption even though there are some rapid strategies, for instance, RSVD used in \cite{rokhlin2009randomized}, \cite{oropeza2011simultaneous} and \cite{chen2016simultaneous}, Lanczos bidiagonalization \citep{gao2013fast}, and the SVD-free methods proposed by \cite{gao2015parallel}. As shown in most seismic processing literature, both groups of methods\dlo{: sparsity-promoting transforms and low-rank approaches} \wen{(sparsity-promoting transforms and low-rank approaches)} can be distinguished by their strength\wen{s} and weakness\wen{es} when recovering seismic data. This idea motivated \cite{sternfels2015multidimensional} to develop an efficient optimization method that constructs a model between sparse inversion technique and low-rank method. Following the same idea, \citet{zhang2017hybrid} \dlo{resolved}\wen{resolves} 3D seismic data simultaneous denoising and interpolation problems, first by designing a rank constraint and sparsity transforms model, and then, by proposing a detailed framework to solve it. This approach successfully removed random noise and reduced computation time. 

\old{In more recent years}\wen{Recently}, \citet{huang2016damped} \dlo{inserted}\wen{insert} a helpful tool called damping operator into the TSVD formula to suppress the remnant noise by RR algorithm. Based on this meaningful theory, 
%\citet{zhang2016multi} first applied the damped rank-reduction (DRR) method to simultaneous denoising and reconstruction, and then, proposed the multistep DRR approach to further enhance its performances.
\citet{chen2016simultaneous} \dlo{extended}\wen{extend} the DRR method \citep{huang2016damped} to 5D seismic data simultaneous denoising and reconstruction. This method shows a superior reconstruction quality even though land seismic data have very low S/Ns. However, this approach has its limits when the \dlo{level}\wen{degree} of missing traces and residual noise increases, which can be explained by the fact that the DRR process certainly reflects the contribution of noise in the approximation signal. That is to say, only using the damping operator as a constraint is not sufficient \dlo{enough}for noise removal. Thus, it is needed to introduce a new improved operator into the DRR framework to effectively remove the random noise and hence, enhance the \dlo{SRN}\wen{S/N}. 

Following \citet{chen2016simultaneous}, we first develop an operator called soft thresholding (ST) moving-average (MA)(STMA) by combining the broadly used \dlo{iterative}ST operator \citep{donoho1995noising,daubechies2004iterative,candes2006robust} and the MA filter \citep{schafer1989discrete}. Then, \wen{by applying the STMA operator to the Hankel matrix after the damped truncated singular value decomposition (DTSVD)}, we construct a connection between STMA \wen{operator} and DRR formula to model a robust damped RR (RDRR) method formula. The proposed approach \dlo{that}aims at straightforwardly applying \dlo{many}\wen{several} operators to restore the useful signal, \dlo{mixes}\wen{mixing} the advantages of the damping\dlo{operator, which is applied after TSVD}\wen{, TSVD,} and STMA operators. \dlo{These useful tools are mixed into the same algorithm.}Thus, the RDRR method offers a higher degree of filter for simultaneous denoising and reconstruction of \dlo{five-dimensional}\wen{5D} seismic data. Using synthetic and field \dlo{five-dimensional}\wen{5D} seismic data sets, we compared the RDRR method with the DRR method. The RDRR method is demonstrated to be better than the DRR method.

\dlo{To better follow this work, w}\wen{W}e subdivide the paper as follows\wen{.}\dlo{:} First, we briefly \dlo{remind}\wen{review} the construction of the well-known level-4 block Hankel matrix and the DRR formulation. Then, we elaborate on our proposed algorithm framework. \dlo{Inspection visual}\wen{Visual inspection} and numerical experiments are given to demonstrate the accuracy of our proposed \dlo{solution}approach for simultaneous denoising and reconstruction of \dlo{five-dimensional}\wen{5D} seismic data. Finally, a
discussion and our conclusions are presented.

\section{\dlo{Theory}\wen{The DRR method}}
\subsection{Constructing a level-4 block Hankel matrix} 

A volume of \dlo{five-dimensions}\wen{5-D} seismic data $\mathbf{D}(t, n_1, n_2, p_1, p_2)$ that depends on the source-receiver positions \dlo{pays our attention}\wen{is the main object} in this paper. The terms $n_1$ and $n_2$ correspond to the receiver coordinates, $p_1$ and $p_2$ are the source positions, and t is the time. \dlo{Such tensor that}\wen{This tensor, which} depends on four spatial \dlo{indices}\wen{dimensions} can be formed by transforming the data to \dlo{a nominal}\wen{the} midpoint-offset domain as \dlo{$\mathbf{D}(t, Nx_1, Nx_2, x_1, x_2)$, where $Nx_1$, $Nx_2$ represent common midpoint positions and $x_1$ and $x_2$ stand for offset coordinates}\wen{$\mathbf{D}(t, hx, hy, x, y)$. The components $hx$, $hy$, $ x $ and $ y $, represent $ x $ and $ y $ offsets and $x$ and $y$ midpoints coordinates}. \dlo{RDRR method for such seismic data recovering can be executed by forming the level-4 block Hankel matrix.}To reach the desired matrix, we first convert the \dlo{five-dimensions}\new{5D} seismic data defined in time-space domain \dlo{$\mathbf{D}(t, Nx_1, Nx_2, x_1, x_2)$ into $\mathbf{D}(\omega, Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}(t, hx, hy, x, y)$ into $\mathbf{D}(\omega, hx, hy, x, y)$} of complex values in the frequency-space domain, where ${t}$ and $\omega$ denote time and frequency components, respectively. Thus, in this process, one can model each observed noisy and incomplete data at a known frequency portion by a four-dimensional spatial multilevel cube $\mathbf{D}_{e_1,e_2,e_3,e_4}$ with $e_i = 1 \cdot\cdot\cdot T_i$, {$i = 1,2,3,4$}, when the spatial variables are regularly sampled. Each frequency portion behaves in the same way. \dlo{RDRR method for such seismic data recovering can be executed by forming the level-4 block Hankel matrix} \dlo{The desired matrix must be closer to a square matrix as clearly outlined in}For simplification, \wen{we use $\textbf{G}$ as our level-4 block Hankel matrix.} 
%\cite{gao2015parallel}. 
\dlo{To succeed, we define parameters $Z_i$ as $\lfloor\frac{T_i}{2}\rfloor+1, i = 1, 2, 3, 4$. The symbol $\lfloor\cdot\rfloor$ corresponds to the integer part of its argument. At a known frequency $\omega_0$, all elements that characterize the seismic data set in the first level of the tensor $\mathbf{D}_{e_1,e_2,e_3,e_4}$ are used to introduce the seismic data first, in a level-1 block Hankel matrix. This operation is done gradually until we reach the size of the desired matrix. This procedure allows constructing the following level-1 block Hankel matrix, which is defined by its size $Z_{1}\times(T_{1}-Z_{1} + 1)$,}
%\begin{equation}
%\textbf{B}^{(l_1)}_{e_2,e_3,e_4}=\begin{bmatrix}
%\textbf{D}_{1,e_2,e_3,e_4} & \textbf{D}_{2,e_2,e_3,e_4} & ... & \textbf{D}_{T_{1}-Z_{1}+1,e_2,e_3,e_4}\\ 
%\textbf{D}_{2,e_2,e_3,e_4} & \textbf{D}_{3,e_2,e_3,e_4} & ... & \textbf{D}_{T_{1}-Z_{1}+2,e_2,e_3,e_4}\\ 
%\vdots & \vdots & \ddots & \vdots\\
%\textbf{D}_{{Z_{1}}{e_2,e_3,e_4}} & \textbf{D}_{{Z_{1}+1},{e_2,e_3,e_4}}  & ... & \textbf{D}_{T_{1},e_2,e_3,e_4}
%\end{bmatrix}.
%\end{equation}
%
%Then, we inserted these matrices shown in eq.(1) in a level-2 block Hankel matrix of size $(Z_{1}Z_{2})\times(T_{1}-Z_{1} + 1)(T_{2}-Z_{2}+1)$.
%
%\begin{equation}
%\textbf{B}^{(l_2)}_{e_3,e_4}=\begin{bmatrix}
%\textbf{B}^{(l_1)}_{1,e_3,e_4} & \textbf{B}^{(l_1)}_{2,e_3,e_4} & ... & \textbf{B}^{(l_1)}_{T_{2}-Z_{2}+1,e_3,e_4}\\ 
%\textbf{B}^{(l_1)}_{2,e_3,e_4} & \textbf{B}^{(1)}_{3,e_3,e_4} & ... & \textbf{B}^{(1)}_{T_{2}-Z_{2}+2,e_3,e_4}\\
%\vdots & \vdots & \ddots & \vdots\\
%\textbf{B}^{(l_1)}_{Z_{3},{e_4}} & \textbf{B}^{(l_1)}_{Z_{2}{+1,e_3,e_4}} & ... & \textbf{B}^{(l_1)}_{T_{2},e_3,e_4}\\ 
%\end{bmatrix}.
%\end{equation}
%
%Eq.(2) corresponds to the level-2 of the desired matrix.\\
%Afterward, the previous matrices are included in a level-3 block Hankel matrix:
%
%\begin{equation}
%\textbf{B}^{(l_3)}_{e_4}=\begin{bmatrix}
%\textbf{B}^{(l_2)}_{1,e_4} & \textbf{B}^{(l_2)}_{2,e_4} & ... & \textbf{B}^{(l_2)}_{T_{3}-Z_{3}+1,e_4}\\ 
%\textbf{B}^{(l_2)}_{2,e_4} & \textbf{B}^{(l_2)}_{3,e_4} & ... & \textbf{B}^{(l_2)}_{T_{3}-Z_{3}+2,e_4}\\ 	
%\vdots & \vdots & \ddots & \vdots\\
%\textbf{B}^{(l_2)}_{Z_{3},e_4} & \textbf{B}^{(l_2)}_{Z_{3},1+e_4} & ... & \textbf{B}^{(l_2)}_{T_{3},e_4}
%\end{bmatrix}.
%\end{equation}
%
%$(Z_{1}Z_{2}Z_{3})\times(T_{1}-Z_{1} + 1)(T_{2}-Z_{2}+1)(T_{3}-Z_{3}+1)$ denotes the size of the matrices in eq.(3).
%
%Finally, we construct the desired matrix by embedding the level-3 block Hankel matrices shown in eq.(3) in a level-4 block Hankel matrix:
%
%\begin{equation}
%\textbf{B}^{(l_4)}=\begin{bmatrix}
%\textbf{B}^{(l_3)}_1 & \textbf{B}^{(l_3)}_2 & ... & \textbf{B}^{(l_3)}_{T_4-Z_4+1}\\ 
%\textbf{B}^{(l_3)}_2 & \textbf{B}^{(l_3)}_3 & ... & \textbf{B}^{(l_3)}_{T_4-Z_4+2}\\ 
%\vdots & \vdots & \ddots & \vdots\\
%\textbf{B}^{(l_3)}_{Z_{4}} & \textbf{B}^{(l_3)}_{Z_{4} +1} & ... & \textbf{B}^{(l_3)}_{T_{4}}
%\end{bmatrix}.
%\end{equation}
%
%Eq.(4) corresponds to the desired matrix. 
%$ \textbf{B} $ and $l_n$ denote respectively the block Hankel matrix and its corresponding level. The size of $\textbf{B}^{(l_4)}$,
%which corresponds to 
%${(Z_1Z_2Z_3Z_4)\times(T_1 - Z_1 + 1)(T_2 - Z_2 + 1)(T_3 - Z_3 + 1)(T_4 - Z_4 + 1)}$ 
%can be written as $(Z_1Z_2Z_3Z_4)\times(Z_1Z_2Z_3Z_4)$ if $T_i$ is an odd integer. 
%For simplification, \wen{we use $\textbf{G}$ as our level-4 block Hankel matrix.}
%\begin{equation}
%\textbf{B}^{(l_4)}= \textbf{G},
%\end{equation}

%where $\textbf{G}$ corresponds henceforward to our level-4 block Hankel matrix.

\subsection{\dlo{DRR method for simultaneous denoising and reconstruction of 5-D seismic data}\wen{Damped TSVD}}

In this section, first we briefly \dlo{remind}\wen{review} the expression of the true model of $\textbf{G}$, and then the basic elements of \wen{the} DRR formula are given.

To simplify notation, it is better to disregard the argument {$e_1, e_2, e_3, e_4$} of {$\mathbf{D}_{e_1,e_2,e_3,e_4}$}. The Hankelization operator \citep{chen2016open,chen2016simultaneous,zhang2017hybrid} converts the \dlo{four-dimensional}\wen{4D} data at a single frequency into the matrix $\textbf{G}$ as follows:
\begin{equation}
\mathbf{G}=h\mathbf{D},                    
\end{equation}
where ${h}$ is the well-known Hankelization operator.

The matrix {$\mathbf{G}$} can be modeled in a general form as:
\begin{equation}
\mathbf{G} = \mathbf{A}+\mathbf{N},                       
\end{equation}
where $\mathbf{A}$ and $\mathbf{N}$ correspond, respectively, to the signal and random noise accumulated during the acquisition process. \dlo{In order t}\wen{T}o formulate the singular value decomposition of $ \mathbf{G} $, we suppose that the rank of {$ \mathbf{G} $} and $\mathbf{N}$ is complete. The size of the matrix {$\mathbf{G}$} can be written as {$I \times J$} with {$J < I$}. {$rank(\mathbf{G})=rank(\mathbf{N}) = J$, $I= Z_1Z_2Z_3Z_4, J= (T_1 -  Z_1 + 1)(T_2 - Z_2 + 1)(T_3 -  Z_3 + 1)(T_4 - Z_4 + 1)$}. The signal {$\mathbf{A}$} has incomplete rank, with {$rank(\mathbf{A})= K < J$}. In these conditions, we write the approximation of {$\mathbf{G}$} as follows:
\begin{equation}
\mathbf{G}=\begin{bmatrix}
U^{\mathbf{G}}_1 & U^{\mathbf{G}}_2\\
\end{bmatrix}
\begin{bmatrix}
\Sigma^{\mathbf{G}}_1 & 0\\
0 & \Sigma^{\mathbf{G}}_2\\
\end{bmatrix}
\begin{bmatrix}
(V^{\mathbf{G}}_1)^{\mathbf{t}}\\
(V^{\mathbf{G}}_2)^{\mathbf{t}}
\end{bmatrix},
\end{equation}
where the first diagonal matrix {$\Sigma^{\mathbf{G}}_1(K\times K)$} is characterized by its larger singular values and the second {$\Sigma^{\mathbf{G}}_2(I -  K) \times(J -  K)$} by its smaller singular values. The conjoint matrices with singular vectors are denoted by {$U^{\mathbf{G}}_1(I \times K)$}, {$U^{\mathbf{G}}_2(I\times(I -  K))$}, {$(V^{\mathbf{G}}_1)^{\mathbf{t}}(J \times K)$} and \dlo{$(V^{\mathbf{G}}_2)^{\mathbf{h}}(J \times(J -  K))$} \wen{$(V^{\mathbf{G}}_2)^{\mathbf{t}}(J \times(J -  K))$}. The conjugate transpose of the matrix is represented by the symbol {$\left(\cdot\right)^{\mathbf{t}}$}. In order to simultaneously denoise and reconstruct the useful signal during the first iteration, we substitute {$\Sigma^{\mathbf{G}}_2$} with {$0$}. This substitution leads to the following \dlo{eq.}\wen{equation} 4, which corresponds to the truncated singular value decomposition (TSVD) formula:
\begin{equation}
\mathbf{\tilde{G}}=U^{\mathbf{G}}_1{\Sigma^{\mathbf{G}}_1}{(V^{\mathbf{G}}_1)^{\mathbf{t}}}.
\end{equation}
\citet{huang2016damped} explain clearly why $\mathbf{\tilde{G}}$ still suffers from residual noise. According to their approach, we express the approximation of {$\mathbf{A}$} as follows:
\begin{equation}
\mathbf{A}=\begin{bmatrix}
U^\mathbf{A}_1 & U^\mathbf{A}_2\\
\end{bmatrix}
\begin{bmatrix}
\Sigma^\mathbf{A}_1 & 0\\
0 & \Sigma^\mathbf{A}_2\\
\end{bmatrix}
\begin{bmatrix}
(V^\mathbf{A}_1)^{\mathbf{t}}\\
(V^\mathbf{A}_2)^{\mathbf{t}}\\
\end{bmatrix}.
\end{equation}
Contrary to {$\mathbf{\tilde{G}}$}, the rank of $\mathbf{A}$ has to be incomplete and {$\Sigma^\mathbf{A}_2$} should be set as zero diagonal matrix\new{,} which allows to express $ \mathbf{A} $ in its short model:
\begin{equation}
\mathbf{A}=U^{\mathbf{A}}_1{\Sigma^{\mathbf{A}}_1}(V^{\mathbf{A}}_1)^{\mathbf{t}}.
\end{equation}
The true model of \wen{$\mathbf{\tilde{G}}$} \dlo{$\mathbf{G}$} (see \dlo{eq.(7)}\wen{equation 7}) can be obtained via the combination of \dlo{eqs (2), (5) and (6)}\new{equations 2, 5 and 6,}\dlo{.}   
\begin{align}
\mathbf{\tilde{G}}= \mathbf{A}+ U^{\mathbf{A}}_1(U^{\mathbf{A}}_1)^{\mathbf{t}}\mathbf{N}.
\end{align}
\dlo{Eq.(7)}\wen{This equation} clearly shows that {$\mathbf{\tilde{G}}$} still suffers from random noise ${U^\mathbf{A}_1(U^\mathbf{A}_1)^{\mathbf{t}}\mathbf{N}}$. Therefore, \citet{chen2016simultaneous} \dlo{extended}\new{extend} \wen{the} DRR algorithm \citep{huang2016damped} to \dlo{five-dimensions}\wen{5-D} seismic data restoration. The approximation of {$\mathbf{A}$} using the DRR \wen{operator} is given as follows:
\begin{align}
\mathbf{A}=U^{\mathbf{G}}_1{\Sigma^{\mathbf{G}}_1}\Lambda\left( V^{\mathbf{G}}_1\right)^{\mathbf{t}},
\end{align}
\begin{align}
\Lambda= I - (\Sigma^{\mathbf{G}}_1 )^{-d}{{\gamma}^d},
\end{align} 
where \wen{${\gamma}$}\dlo{${\gamma}^d$} represents the maximum element of {$\Sigma^{\mathbf{G}}_2$}\wen{.}\dlo{and} $d$ corresponds to the damping factor. \dlo{$\Lambda$ loses its abilities when $d$ increases gradually and eq.(8) tends towards eq.(4)}\wen{DRR reverts to the traditional method} when {$d\rightarrow+\infty$}. \dlo{Eq.(8) indicates the formula of the DRR method.}

\section{\dlo{The RDRR method for simultaneous denoising and reconstruction of 5-D seismic data}\wen{The RDRR method}}

Following \cite{chen2016simultaneous}, we focus on the approximation of $\mathbf{A}$ to restore the \dlo{serviceable}\wen{useful} events from $\mathbf{G}$. As shown in \old{eq.(8)}\new{equation 8}, the estimated signal $\mathbf{A}$ is influenced by the introduced damping operator $(\Lambda)$. This mathematical relationship between $\Lambda$ (see \dlo{eq.(9)}\new{equation 9}) and the TSVD formula (see \dlo{eq.(4)}\wen{equation 4}) corresponds to the DRR formula. 
\wen{Based on \dlo{eqs (8) and (9)}\wen{equations 8 and 9}, the original signal can be regarded as a damped version of the TSVD result $\mathbf{\tilde{G}}$ in \dlo{eq.(4)}\new{equation 4} \citep{chen2016simultaneous}. By considering the formula of the DRR method, the approximation signal should be very close to the original signal. However, that is not verified when the data to be restored \dlo{is}\wen{are} corrupted by a high noise level and percentage of missing traces. In this paper, we assign the term coefficients to the values of the observed data that can be transformed by the DTSVD to obtain the useful signal. In the DRR approach, the observation matrix $\mathbf{G}$ is transformed by the DTSVD process to compute the signal matrix $\mathbf{A}$. The resulting \dlo{four-dimensional}\wen{4D} signal matrix $\mathbf{A}\in R^{J \times I}$ consists of the transformed coefficients. In this work,} we assume that the small \dlo{transform}\wen{transformed} coefficients, which correspond to the unwanted values in $\mathbf{A}$ \wen{obtained after} \dlo{during the DRR process certainly reflect the contributions from noise}\wen{the DTSVD process\wen{,} essentially correspond to noise}. This assumption can explain the residual noise that still \dlo{contains}\wen{remains in} the results of the DRR method. Thus, it is \dlo{needed}\wen{demanded} to handle the \dlo{transform}\wen{transformed coefficients of the approximation matrix $\mathbf{A}$ (\dlo{eq.(8)}\wen{equation 8}), which is obtained after DTSVD} by introducing an improved operator into the framework of the DRR algorithm, which aims at effectively attenuating the random noise while reconstructing the useful signal.

\subsection*{\dlo{Regularized iterative}ST}

Broadly utilized to promote sparsity \citep{donoho1995noising,figueiredo2003algorithm,daubechies2004iterative}, the ST operator can be applied to a signal $\mathbf{X}$ \dlo{in order} to minimize the contribution of noise. Based on this advantage, we first impose sparsity in the Hankel matrix $\mathbf{G}$ by applying \dlo{iterative} \wen{the} ST operator on the representation signal $\textbf{X}$, which is calculated with respect to the DRR framework. \dlo{This technique, known as iterative regularization}\wen{The ST function} \citep{donoho1995noising,candes2010matrix,yeganli2017noise} is given by:  
\begin{equation}
Is_\tau\left(\mathbf{X}\right)=sgn(\mathbf{X})\cdot max(0,{\mid \mathbf{X} \mid - \mid \tau \mid}),
\end{equation}
where \textbf{X} denotes the signal to be approximated, $Is_\tau\left(\mathbf{X}\right)$ corresponds to the transformed signal after applying \dlo{the regularized iterative}the soft thresholding operator $IS_\tau$, and $sgn( \textbf{X})$ is the signum function. The ST operator shrinks each coefficient of the signal by the amount of $\tau$ called ST parameter. 

In this paper, we propose to set $\tau$ as follows:
\begin{equation}
\tau=\frac{\beta \cdot \lambda}{\alpha},
\end{equation}
where $\lambda$ denotes the regularization operator $\alpha$ is the scaling parameter used to manage $\tau$, and $\beta$ is the \dlo{decrease}\wen{decreasing} factor for cooling \dlo{lambda}\wen{$\lambda$}. Note that $\beta$ is a given value $\in$ R used to regulate $\tau$. This parameter provides us much freedom to control the simultaneous denoising and reconstruction operation.

We estimate $\lambda$ and $\alpha$ through the \dlo{following}linear forward model \wen{for the following} recovery problem defined in \cite{hennenfent2008sampling}:
\begin{equation}
\mathbf{Y}=L\mathbf{M},
\end{equation}
where $\mathbf{Y}$ represents the sampled entries and ${L}$ denotes the restriction operator that put together the acquired samples from the model in \dlo{eq.(12)}\wen{equation 12}. The term ${L}$ is applied to the vectorized $\textbf{M}$ of the signal $\mathbf{X}$. In forward mode, ${L}$ selects certain entries from $\mathbf{X}$ and returns a corresponding shortened vector. 

Considering the model in \old{eq.(12)}\new{equation 12}, we set $\lambda$ and $\alpha$ as follows:
\begin{equation}
\lambda=\beta \cdot \left\| max\left(\mid \mathbf{Y} \mid \right) \right\|_0, 
\end{equation}
\begin{equation}
\alpha=\sigma \cdot \left(\left\| max\left(\mid \mathbf{Y} \mid \right) \right\|_0 + \sqrt{length(\mathbf{Y})} \right),
\end{equation}
where $\left\|\cdot\right\|_0$ corresponds to the $l_0$ norm and $\sigma$ stands for the noise standard deviation in $\mathbf{Y}$.\\ 

From \dlo{eq.(10)}\wen{equation 10}, it is obvious that $IS_\tau$ can be directly applied to the approximation signal \wen{$\mathbf{A}$} using the DRR method \wen{to nullify the coefficients below a fixed threshold}. Thus, \wen{by} using $IS_\tau$, we transform \dlo{eq.(8)}\new{equation 8} as follows:
\begin{align}
\nonumber
Is_\tau\left(\mathbf{A}\right)&=sgn(\mathbf{A})\cdot max(0,{\mid \mathbf{A} \mid - \mid \tau \mid})\\
\nonumber
&=sgn({U^{\mathbf{G}}_1{\Sigma^{\mathbf{G}}_1}\Lambda\left( V^{\mathbf{G}}_1\right)^{\mathbf{t}}})\cdot max(0,{\mid {U^{\mathbf{G}}_1{\Sigma^{\mathbf{G}}_1}\Lambda\left( V^{\mathbf{G}}_1\right)^{\mathbf{t}}} \mid - \mid \tau \mid}),\\
Is_\tau\left(\mathbf{A}\right)&\approx \mathbf{A}_\tau,
\end{align}
where $\mathbf{A}_\tau$ denotes the approximation \wen{signal} using both the damping and \dlo{iterative}ST operators.

\subsection*{MA filter} 

The MA filter is broadly used for smoothing an array of the sampled signal. A significant gain of MA is its random noise attenuation capability while preserving the \dlo{serviceable}\wen{useful} signal response. The following difference equation explains a \dlo{MAF}\wen{MA} of the signal $\mathbf{X}$:
\begin{equation}
\mathbf{X}[i] =\frac{1}{T}\sum_{J=0}^{T-1}\mathbf{X}\left[i-j\right],   
\end{equation}                                               
where $T$ denotes the number of filter coefficients (also known as filter length) and $T -1$ corresponds to the filter order.

\old{Eq.(16)}\new{Equation 16} operates on an input signal $\mathbf{X}$ using the following rational transfer function:  

\begin{equation}
{M(y)=\frac{q(1)+q(2)y^{-1}+...+q(t_q + 1)y^{-t_q}}{1+r(2)y^{-1} +...+ r(t_r+1)y^{-t_r}}}{N(y)}\dlo{,}\wen{.}
\end{equation}

\dlo{Eq.(17)}\wen{Equation 17} shows the relationship between the rational transfer function $M(y)$ of a discrete-time filter's output \dlo{$m(i)$}\wen{$M(i)$} and rational transfer function $N(y)$ of the input $N(i)$. The terms ${q_i}$ and ${r_i}$ are the filter coefficients, $t_r$ designates the feedback filter order, and $t_q$ corresponds to the feed-forward filter order. Due to normalization, we assume $r(1) = 1$ \citep{schafer1989discrete}.

The MA filter transforms $\mathbf{A}$ in \dlo{eq.(12)}\wen{\dlo{eq.(8)}\wen{equation 8}} \dlo{as follows}\wen{as follows}:
\begin{align}
\nonumber
\mathbf{A}[i]  &=\frac{1}{T}\sum_{J=0}^{T-1}\mathbf{A}\left[i-j\right]\\\nonumber
&=\frac{1}{T}\sum_{J=0}^{T-1}{\left( U^{\mathbf{G}}_1{\Sigma^{\mathbf{G}}_1}\Lambda\left( V^{\mathbf{G}}_1\right)^{\mathbf{t}}\right) }\left[i-j\right],\\
\mathbf{A}[i] &\approx \mathbf{A}_m, 
\end{align}
where $\mathbf{A}_m$ denotes the approximation \wen{signal} using the damping \wen{operator} and the MA filter.\\

Our experience with both operators above shows that each of them has a significant advantage in \dlo{reconstructing the signal}\wen{attenuating the contribution of residual noise in the approximation signal $\mathbf{A}$}. Therefore, \wen{by} combining the two operators, we can simultaneously take advantages of them for high accuracy.  

\subsection*{\dlo{Connection between}\wen{Combining} ST and MA: STMA operator}

As shown, the \dlo{regularized iterative}ST and the MA \wen{operators} can be applied directly to the \wen{approximation} signal $\mathbf{A}$ \wen{after DTSVD}. Thus, a connection can be established to develop a novel improved operator called STMA operator, which can be applied directly to the \wen{approximation} signal \wen{$\mathbf{A}$ after DTSVD}. Combining \dlo{eq\wen{s}.(10) and (16)}\wen{equations 10 and 16}, we design the mathematical relationship between the ST and the MA filter as follows:
\begin{equation}
\mathbf{X}[i]  =\frac{1}{T}\sum_{J=0}^{T-1}{ Is_{\tau}\left(\mathbf{X}\right)} \left[i-j\right].   
\end{equation}   
\dlo{Eq.(19)}\wen{Equation 19} denotes the STMA operator, which results from the combination of the \dlo{iterative}ST \wen{operator \citep{donoho1995noising}} and the MA filter \wen{\citep{schafer1989discrete}}. 

\wen{The proposed operator that we call STMA is used to nullify the unwanted value (also known as small transformed coefficients) in $\mathbf{A}$ after DTSVD. This operation \dlo{leads to compensate}\wen{compensates} for the DRR method operator, which has been introduced to attenuate the random noise after the conventional TSVD process. The STMA operator aids at \dlo{enhance}\wen{enhancing} the quality of the signal provided by the DRR method. This operator can be seen as an improved proximity function used to minimize the contribution of random noise at a lower level. We connect this function to the DRR framework after DTSVD to further \dlo{afford}\wen{provide} an accurate approximation signal matrix $\mathbf{A}$}.   

\subsection*{\dlo{Connection between}\wen{Combining} STMA and DRR formula: RDRR}

In this section, we establish a connection between STMA and DRR formula to construct the proposed \dlo{program}\wen{algorithm}. This novel algorithm \dlo{aspires}\wen{aims} at mixing the benefits of both operators: damping and STMA operators \wen{to improve the quality of $ \mathbf{A}$ defined in \dlo{eq.(8)}\wen{equation 8}}. The resulting filter obtained via this combination can be regarded as applying \wen{an enhanced filter} \dlo{multiple operators} for simultaneous denoising and reconstruction of 5D seismic data.\\
The operation of STMA transforms the DRR method for 5D interpolation into an \dlo{improve}\wen{improved} method called RDRR method. The approximation of the signal $\mathbf{A}$ using the RDRR method can be formulated as follows:
\begin{align}
\nonumber
\mathbf{A}[i] & =\frac{1}{T}\sum_{J=0}^{T-1}Is_{\tau}\left(U^{\mathbf{G}}_1\Sigma^{\mathbf{G}}_{1}\Lambda(V^{\mathbf{G}}_1)^{{t}}\right)\left[i-j\right],\\
\mathbf{A}[i]&\approx \mathbf{\tilde{A}},
\end{align}   
where $\mathbf{\tilde{A}}$ denotes the approximation signal using the proposed \dlo{program}\wen{algorithm}.\\
\wen{The} RDRR method requires five \dlo{keys}\wen{key} parameters: the rank constraint ($K$) used in the conventional RR method; the damping factor ($d$) used in DRR method, the ST parameter ($\tau$), the rational transfer \wen{function} coefficient ($e$), (here e serves as a scaling factor
of the moving average filter, i.e., in equation 17, $r(1) = e$, $t_r = 0$), and the window size ($T$) used in STMA operator. Note that, $\tau$ is adjusted and controlled by a given value {$\beta$} {$\in R$} called \wen{the} cooling factor.    

We model the relationship between $\mathbf{\tilde{A}}$, $\mathbf{{G}}$ and the improved DRR algorithm operator as follows:
\begin{equation}
\mathbf{\tilde{A}}={R}_{d\tau_m}{\mathbf{{G}}}, 
\end{equation}
where ${R}_{d\tau_m}$ is the RDRR operator whereas ${R}_d$ is used for the DRR.

Afterward, we apply the averaging function \citep{chen2016open} along the anti-diagonals of $\mathbf{\tilde{A}}$ in the following way:
%\old{
\begin{equation}
\mathbf{\hat{D}}={L}\mathbf{\tilde{A}}={L}{R}_{d\tau_m}\mathbf{G}={{L}}{{R}}_{d\tau_m}{{{h}}\mathbf{D}}={F}_{d\tau_m}\mathbf{D}.
\end{equation}
%}
${L} $ is the averaging operator. ${F}_{d\tau_m}$ and ${R}_{d\tau_m}$ are respectively the robust damped rank-reduction filter and operator, and ${R}_d$ and ${F}_d$ are used for damped rank-reduction operator and filter, respectively.

The following \dlo{eq.(23)}\new{equation 23} designates the weighted iterative algorithm based on DRR method:
\begin{equation}
\mathbf{D}_i= a_{i}\mathbf{D}_{ob} + (1 - a_{i}{T})\circ {F}_{d}\mathbf{D}_{i - 1}, \quad i = 1, 2, 3, . . . , i_{max}, 
\end{equation}
where ${F}_d$ denotes the DRR filter.

Using the RDRR filter $({F}_{d\tau_m})$, we \dlo{review the DRR program and}formulate our proposed algorithm for simultaneous denoising and reconstruction of 5-D seismic data as follows:
\begin{equation}
\mathbf{D}_i= a_{i}\mathbf{D}_{ob} + (1 - a_{i}{T})\circ {F}_{d\tau_m}\mathbf{D}_{i - 1}, \quad i = 1, 2, 3, . . . , i_{max}, 
\end{equation}
where $\mathbf{D}_0 = \mathbf{D}_{ob}$ corresponds to the observed noisy and incomplete data. The coefficient $a_{i}$ is an iteration scalar, which strictly diminish from $a_1=1$ to $a_{i_{max}}=0$. The term ${T}$ denotes the sampling operator. Furthermore, the elements of ${T}$ are equal to 1 when $ \mathbf{D}_{ob} $ is not empty, otherwise $0$ at the missing values. The symbol $\circ$ corresponds to the Hadamard product of two entities with the same size.\\

\dlo{Below is outlined t}\wen{T}he DRR algorithm \dlo{adopted}for simultaneous denoising and reconstruction of 5D seismic data \wen{is outlined as follows:}

\begin{center}
	\begin{algorithm}[H]
		\DontPrintSemicolon
		\dlo{$\mathbf{D}_{ob}(f, Nx_1, Nx_2, x_1, x_2)\leftarrow \mathbf{D}_{ob}(t, Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{ob}(f,hx, hy, x, y)\leftarrow \mathbf{D}_{ob}(t,hx, hy, x, y)$} via 1D forward FFT\;    
		$\mathbf{D}_0\leftarrow\mathbf{D}_{ob}$\;
		\For{$f\leftarrow 1,2,\dots,{F}$}{
			\For{$i\leftarrow 1,2,\dots,i_{max}$}{
				$\mathbf{D}^f_i \leftarrow a_i\mathbf{D}^f_{ob} + (1 - a_i){TF}_{d}\mathbf{D}^f_{i-1} + (1 - {T}){F}_{d}\mathbf{D}^f_{i-1}$\;
				\If{$\left\|\mathbf{D}^f_i - \mathbf{D}^f_{i-1}\right\|_F^2\leq\epsilon$}{
					\textbf{return} $\mathbf{D}^f_i$\;
				}
				\textbf{return} $\mathbf{D}^f_{i_{max}}$\;
			}
			\textbf{return} $\mathbf{D}_{recovered}$\;
		}
		\dlo{$\mathbf{D}_{recovered}(t,Nx_1, Nx_2, x_1, x_2)\leftarrow \mathbf{D}_{recovered}(f,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{recovered}(t,hx, hy, x, y)\leftarrow \mathbf{D}_{recovered}(f,hx, hy, x, y)$} via 1D inverse FFT\;
		
		\caption{Damped rank-reduction ({${T}$}, {${F}_{d}$}, {$\mathbf{D}_{ob}$}, {$a_{i}$}, \dlo{${Tol}$}\wen{$\epsilon$}, {$i_{max}$}, {${F}$})}
		
	\end{algorithm}
\end{center}

The following workflow presents our proposed RDRR algorithm for simultaneous denoising and reconstruction of 5D seismic data:

\begin{center}
	\begin{algorithm}[H]
		\DontPrintSemicolon
		\dlo{$\mathbf{D}_{ob}(f,Nx_1, Nx_2, x_1, x_2)\leftarrow \mathbf{D}_{obs}(t,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{ob}(f,hx, hy, x, y)\leftarrow \mathbf{D}_{obs}(t,hx, hy, x, y)$} via 1D forward FFT\;    
		$\mathbf{D}_0\leftarrow\mathbf{D}_{ob}$\;
		\For{$f\leftarrow 1,2,\dots,{F}$}{
			\For{$n\leftarrow 1,2,\dots,i_{max}$}{
				$\mathbf{D}^f_i \leftarrow a_i\mathbf{D}^f_{ob} + (1 - a_i){TF}_{d\tau_m}\mathbf{D}^f_{i-1} + (1 - {T}){F}_{d\tau_m}\mathbf{D}^f_{i-1}$\;
				\If{$\left\|\mathbf{D}^f_i - \mathbf{D}^f_{i-1}\right\|_F^2\leq\epsilon$}{
					\textbf{return} $\mathbf{D}^f_i$\;
				}
				\textbf{return} $\mathbf{D}^f_{i_{max}}$\;
			}
			\textbf{return} $\mathbf{D}_{recovered}$\;
		}
		\dlo{$\mathbf{D}_{recovered}(t,Nx_1, Nx_2, x_1, x_2)\leftarrow \mathbf{D}_{recovered}(f,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{recovered}(t,hx, hy, x, y)\leftarrow \mathbf{D}_{recovered}(f,hx, hy, x, y)$} by 1D inverse FFT\;		
		\caption{Robust damped rank-reduction ($T$, {${F}_{d\tau_m}$}, $\mathbf{D}_{ob}$, $a_{i}$, \dlo{${Tol}$}\wen{$\epsilon$}, $i_{max}$, $F$)}
	\end{algorithm}
\end{center}

In both algorithms, when the frequencies denoted by ${F}$ are completed, the process of iteration stops immediately. Besides, the algorithms stop running according to two independent \dlo{principles :}\wen{principles:} (1) when {$i_{max}$} that corresponds to the maximum number of iterations is \dlo{achieved}\wen{reached} and (2) when {$\left\|\mathbf{D}^f_i - \mathbf{D}^f_{i-1}\right\|_F^2\leq \epsilon$} for each ${F}$ portion. The term $\epsilon$ is a given small tolerance and the symbol {$\left\|\cdot\right\|_F$} corresponds to the Frobenuis norm. The main difference between DRR framework and the proposed RDRR algorithm is the filter {${F}_{d\tau_m}$}. Here is a short \dlo{detail}\wen{description} of the proposed algorithm. First, we convert the observed 5D seismic data from time domain \dlo{$\mathbf{D}_{ob}(t,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{ob}(t,hx, hy, x, y)$} into the frequency domain \dlo{$\mathbf{D}_{ob}(f,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{ob}(f,hx, hy, x, y)$}. Then, for each outward loop, we remove noise and reconstruct the entire incomplete data {$\mathbf{D}_{ob}$} for all ${F}$ components. Inside the loop, we use the improved filter {${F}_{d\tau_m}$} included in the weighted POCS-like algorithm. Finally, the recovered data \dlo{$\mathbf{D}_{recovered}(f,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{recovered}(f,hx, hy, x, y)$} obtained in the frequency domain are converted back into the time domain \dlo{$\mathbf{D}_{recovered}(t,Nx_1, Nx_2, x_1, x_2)$}\wen{$\mathbf{D}_{recovered}(t,hx, hy, x, y)$}.

\section{Examples}

Using \dlo{one}\wen{two} synthetic 5D data, \dlo{first,}we conduct many tests with different iteration numbers, noise levels, and percentage of missing data. Then, we use three 5D synthetic data of different sizes to estimate the computation time. At last, \dlo{one}field 5D seismic data is used to verify the performance of the proposed algorithm.

\dlo{In order t}\wen{T}o quantitatively compare the recovering quality of both approaches, we first use the widely used S/N \citep{chen2016simultaneous,zhang2017hybrid} formulated as follows:
\begin{equation}
S/N =10\log_{10}\frac{\Vert \mathbf{X^{c}} \Vert^2_2}{\Vert \mathbf{X^{c}}-\mathbf{X^{r}}\Vert^2_2},
\end{equation}
where $\mathbf{X^{c}}$ corresponds to the vectorized clean data and $\mathbf{X^{r}}$ indicates the vectorized restored data.

Then, we use the commonly used root-square-mean error (rms error) defined as follows to measure the accuracy of each approach:
\begin{equation}
rms\quad error={\sqrt{\frac{1}{N}\sum_{\mathbf{i}=1}^{N}(\mathbf{X^{c}_i-\mathbf{X^{r}})^2}}}\times100,
\end{equation}
where $\mathbf{X^{c}_i}$ denotes the original data and $\mathbf{X^{r}}$ is the simultaneously denoised and reconstructed data.

%\old{Finally, we use the percentage of similarity defined below to further quantify the performance of the robust damped rank-reduction method:	
%\begin{equation}
%\mathbf{S}=\frac{mean(\mathbf{X^{c}}-\mathbf{X^{r}})^2\times100}{mean\left(\mathbf{X^{c}}\right)^2},
%\end{equation}
%}
%\old{
%where $\mathbf{S}$ denotes the percentage of similarity, $\mathbf{X^{c}}$ and $\mathbf{X^{r}}$ are the vectorized original data and the vectorized restored data, respectively. The range of $\mathbf{S}$ is from 0 to 100\%. The lower percentage of similarity will denote better restoration performance.} 

\subsection{Synthetic data examples}

To demonstrate the performance of the proposed algorithm, we apply both methods \wen{first, on 5D synthetic seismic data set that is composed of linear events and then curved events. \dlo{The four spatial dimensions of both 5D data are $hx$, $hy$, $x$ and $y$}}   

\wen{For the first case,} we generate a 5D data model with the size of $100 \times 12 \times 12 \times 12 \times 12$, \wen{where}\dlo{which is composed of linear events.} $12 \times 12 \times 12 \times 12$ denotes the spatial size of the model. \wen{We conduct many experiments with this data}. In the first experiment, we randomly decimate $70\%$ of the traces and add a noise \dlo{variance of 0.3}\wen{of 0.3 variance} to examine the simultaneous denoising and reconstruction quality of both algorithms. The 3D figures in one common-midpoint gather \dlo{($Nx_1$ = 6, $Nx_2$ = 6)}\wen{($x$ = 6, $y$ = 6)} and one common-offset gather \dlo{($x_1$ = 6, $x_2$ = 6)}\wen{($hx$ = 6, $hy$ = 6)} of the true, noisy, and decimated data are presented in Figures \ref{fig:synth-clean-hxhy}\dlo{(a)}-\ref{fig:synth-obs-hxhy}\dlo{(c)} and \ref{fig:synth-clean-hxhy}\dlo{(a)}-\ref{fig:synth-obs-hxhy}\dlo{(c)}, respectively. 

The S/N\wen{s} of the noisy and observed data are extremely low with values of {$-$5.38 dB} and {$-$2.40 dB}, respectively. It is difficult to detect any coherent \dlo{valid}events in the observed noisy and incomplete data. To restore the useful signal, we use a rank {$K$ = 6} and a damped factor {$d$ = 2} for the DRR approach. Figures \ref{fig:synth-drr-hxhy}\dlo{(d)} and \ref{fig:synth-drr-xy}\dlo{(d)} show the results obtained using the DRR method. The simultaneously denoised and reconstructed data are satisfactory. Indeed, almost all signals are restored and the random noise has been perfectly reduced. However, the visual examination reveals some residual noise in the results. Using the proposed algorithm, with the same parameters used for DRR approach, we use a valid combination of cooling factor ${\beta = 3.3}$, rational transfer function coefficient ${e = 0.972}$, and window size ${T = 1}$. We run both methods using \dlo{ten}\wen{10} weighted POCS-like iterations. Figures \ref{fig:synth-rdrr-hxhy}\dlo{(e)} and \ref{fig:synth-rdrr-xy}\dlo{(e)} show the results obtained via the proposed RR approach. Compared with the DRR results, our method greatly removes the residual noise and recovers the useful signal. The output S/Ns for the DRR and the proposed approaches are {$15.55$} and {$21.89$ dB}, respectively. From the visual examination and the S/Ns comparison, we deduce that the restoration of the useful signal by the proposed approach is better than the DRR method.

\AtEndDocument{
	\begin{center}
		\begin{table}[h]
			\caption{Comparison of running time of the DRR and the proposed approach for different data sizes after \dlo{10}\wen{ten} iterations and a frequency band of $0-100$ Hz based on an Intel Core i7 7th Gen.}
			\begin{tabular}{c c c c c c} 
				\hline Test &$100\times8\times8\times8\times8$
				& $100\times10\times10\times10\times10$  & $100\times12\times12\times12\times12$ & \\ 
				\hline \dlo{DMSSA} \wen{DRR} (s) & 57.83 & 495.14 & 4419.36\\
				Proposed (s) & 48.64 & 469.69 & 4359.02 \\
				\hline
			\end{tabular} 
			\label{tbl:table1}
		\end{table}
	\end{center}
}
\wen{
	\AtEndDocument{
		\begin{center}
			\begin{table}[htb!]
				\caption{Comparison of S/N values among the ST, MA, STMA, RR, RR + ST, RR + MA, RR + damping factor (DRR), DRR + ST, RR + STMA, DRR + MA, and DRR + STMA (RDRR) for $0.3$ as noise variance and $70\%$ missing traces after \dlo{ten}\wen{10} iterations.}
				\begin{tabular}{c c c c c c} 
					\hline Approaches & S/N (dB) after 10 weighted {POCS-like} iterations & \\ 
					\hline ST& -1.77 & \\
					MA & 9.20 & \\
					STMA & 9.97 &\\
					RR & 11.83 &\\
					RR + ST & 11.83 &\\
					RR + MA &12.51&\\
					RR + damping factor (DRR) &15.55&\\
					RR + damping factor + ST & 15.55 &\\
					RR + STMA & 17.01 &\\
					RR + damping fator + MA & 21.17 &\\
					RR + damping factor + STMA (RDRR) & 21.89 &\\
					\hline
				\end{tabular} 
				\label{tbl:table2}
			\end{table}
		\end{center}
}}
%\AtEndDocument{
%	\begin{figure}[htb!]
%		\centering
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/cmp_originalfinal}
%			\label{Figure:cmp_originalfinal}}
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/cmp_noisyfinal}
%			\label{Figure:cmp_noisyfinal}}
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/cmp_observedfinal}
%			\label{Figure:cmp_observedfinal}}\\	
%		\centering
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/cmp_drrokfinal}
%			\label{Figure:cmp_drrokfinal}}
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/cmp_proposedfinal}
%			\label{Figure:cmp_proposedfinal}}	
%		\caption{Common midpoint 3-D figures comparison ($x$ = 6, $y$ = 6) between \dlo{both}\wen{two} algorithms after \dlo{10}\wen{ten} iterations. (a) Clean data. (b) Noisy data with $ 0.3 $ as noise level. (c) Observed noisy and incomplete data with $70\%$ of missing traces. (d and e) Simultaneously denoised and reconstructed data using the DRR method and the proposed method, respectively.}
%		\label{Figure:cmp_originalfinal,cmp_noisyfinal,cmp_observedfinal,cmp_drrokfinal,cmp_proposedfinal}
%	\end{figure}%fig.1

\inputdir{synth_Linear_NV03_MT70}
\multiplot{5}{synth-clean-hxhy,synth-noisy-hxhy,synth-obs-hxhy,synth-drr-hxhy,synth-rdrr-hxhy}{width=0.3\textwidth}{Common-midpoint 3D figures comparison ($x$ = 6, $y$ = 6) between \dlo{both}\wen{two} algorithms after \dlo{ten}\wen{10} iterations. (a) Clean data. (b) Noisy data with $0.3$ as noise level. (c) Observed noisy and incomplete data with $70\%$ of missing traces. (d and e) Simultaneously denoised and reconstructed data using the DRR method and the proposed method, respectively.}

%\begin{figure}[htb!]
%	\centering
%	\subfloat[]{\includegraphics[width=0.35\textwidth]{synth_Linear_NV03_MT70/Fig/synth-clean-hxhy}\label{Figure:synth-clean-hxhy}}
%	\subfloat[]{\includegraphics[width=0.35\textwidth]{synth_Linear_NV03_MT70/Fig/synth-noisy-hxhy}\label{Figure:synth-noisy-hxhy}}
%	\subfloat[]{\includegraphics[width=0.35\textwidth]{synth_Linear_NV03_MT70/Fig/synth-obs-hxhy}\label{Figure:synth-obs-hxhy}}\\
%	\subfloat[]{\includegraphics[width=0.35\textwidth]{synth_Linear_NV03_MT70/Fig/synth-drr-hxhy}\label{Figure:synth-drr-hxhy}}
%	\subfloat[]{\includegraphics[width=0.35\textwidth]{synth_Linear_NV03_MT70/Fig/synth-rdrr-hxhy}\label{Figure:synth-rdrr-hxhy}}
%	\caption{Common-midpoint 3D figures comparison ($x$ = 6, $y$ = 6) between \dlo{both}\wen{two} algorithms after \dlo{ten}\wen{10} iterations. (a) Clean data. (b) Noisy data with $0.3$ as noise level. (c) Observed noisy and incomplete data with $70\%$ of missing traces. (d %and e) Simultaneously denoised and reconstructed data using the DRR method and the proposed method, respectively.}
%	\label{Figure:synth-clean-hxhy,synth-noisy-hxhy,synth-obs-hxhy,synth-drr-hxhy,synth-rdrr-hxhy}
%\end{figure}%fig.1
%\begin{figure}[htb!]
%		\centering
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/offset_originalfinal}
%			\label{Figure:offset_originalfinal}}
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/offset_noisyfinal}
%			\label{Figure:offset_noisyfinal}}
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/offset_observedfinal}
%			\label{Figure:offset_observedfinal}}
		
%		\centering
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/offset_drrokfinal}
%			\label{Figure:offset_drrokfinal}}
%		\subfloat[]{\includegraphics[width=0.3\textwidth]{Figures/offset_proposedfinal}
%			\label{Figure:offset_proposedfinal}}
%		\caption{Common offset gather 3-D figures comparison ($hx$ = 6, $hy$ = 6) between \dlo{both}\wen{two} algorithms after \dlo{10}\wen{ten} iterations. (a) True data. (b) Noisy data with $ 0.3 $ as noise level. (c) Observed noisy and incomplete data with $ 70\% $ of %missing traces. (d and e) Simultaneously denoised and reconstructed data using the DRR method and the proposed approach, respectively.}
%		\label{Figure:offset_originalfinal,offset_noisyfinal,offset_observedfinal,offset_drrokfinal,offset_proposedfinal}
%	\end{figure}%fig.2

\inputdir{synth_Linear_NV03_MT70}
\multiplot{5}{synth-clean-xy,synth-noisy-xy,synth-obs-xy,synth-drr-xy,synth-rdrr-xy}{width=0.3\textwidth}{Common-offset gather 3D figures comparison ($hx$ = 6, $hy$ = 6) between \dlo{both}\wen{two} algorithms after \dlo{ten}\wen{10} iterations. (a) True data. (b) Noisy data with $0.3$ as noise level. (c) Observed noisy and incomplete data with $70\%$ of missing traces. (d and e) Simultaneously denoised and reconstructed data using the DRR method and the proposed approach, respectively.}


To see the difference more clearly, we display the rms error results obtained by subtracting the recovered data from the original data in \wen{Figure \ref{fig:synth-drr-hxhy-e,synth-rdrr-hxhy-e,synth-drr-xy-e,synth-rdrr-xy-e}. Figures \ref{fig:synth-drr-hxhy-e}\dlo{(a)} and \ref{fig:synth-drr-xy-e}\dlo{(c)} correspond to the DRR approach with rms error values of $2.22\%$ and $2.64\%$ respectively in one common-midpoint and common-offset gather. Figure \ref{fig:synth-rdrr-hxhy-e}\dlo{(b)} and \ref{fig:synth-rdrr-xy}\dlo{(d)} is from the proposed algorithm with rms error values of $1.53\% $ and $1.48\% $ respectively in one common-midpoint and common-offset gathers.} From this comparison, it is \dlo{further} apparent that our approach performs better with fewer denoising and reconstruction errors and thus can provide a better simultaneously denoised and reconstructed improvement than the DRR algorithm. This comparison confirms the superiority of our approach in terms of accuracy. 

\inputdir{synth_Linear_NV03_MT70}
\multiplot{4}{synth-drr-hxhy-e,synth-rdrr-hxhy-e,synth-drr-xy-e,synth-rdrr-xy-e}{width=0.35\textwidth}{Simultaneous denoising and reconstruction error \wen{3D figures} comparison between \dlo{both}\wen{two} algorithms after \dlo{wen}\wen{10} iterations. (a and c) show the DRR approach with rms error values of $2.22\%$ and $2.64\%$ in one common-midpoint and one common-offset gather, respectively. (b and d) correspond to the proposed approach with rms error values of $1.53\%$ and $1.48\%$ in one common-midpoint and one common-offset gather, respectively.}

\wen{Moreover,} we conduct a comparison between the amplitude of each corresponding \dlo{5-D}data \wen{plotted in Figure \ref{fig:synth-clean-hxhy,synth-noisy-hxhy,synth-obs-hxhy,synth-drr-hxhy,synth-rdrr-hxhy}} to highlight more distinctly the differences. Figure \dlo{\ref{fig:7}}\wen{\ref{fig:synth-ss}} displays a comparison between each amplitude. The green, yellow and black lines are, respectively, from the original, noisy, and observed data. The amplitude of the observed data cannot be detected in this figure due to the influence \dlo{of the percentage}of missing traces. The blue and red lines correspond to the DRR approach and proposed approach, respectively. Clearly shown in Figure \dlo{\ref{fig:7}}\wen{\ref{fig:synth-ss}}, the blue and red lines are very regular in most areas. However, we find that the green and red lines are \dlo{too much close} \wen{much closer} to each other. This comparison further demonstrates the high accuracy of the proposed algorithm.

\inputdir{synth_Linear_NV03_MT70}
\plot{synth-ss}{width=0.8\columnwidth}{Comparison of a single trace amplitude of each \dlo{5-D synthetic} data \wen{shown in Figure \ref{fig:synth-clean-hxhy,synth-noisy-hxhy,synth-obs-hxhy,synth-drr-hxhy,synth-rdrr-hxhy}}. The green line is from the clean data. The yellow line denotes the noisy data. The amplitude of the observed data denoted by the black line is zero and thus cannot be seen from the figure. The blue line corresponds to the DRR method. The red line corresponds to the proposed method. The proposed method can provide a good amplitude very close to the clean compared to the DRR method.}

\dlo{We further compare the performance of the DRR method and our approach from another aspect using the amplitude \dlo{and frequency-space (f-x)} spectra. According to the amplitude spectrum comparison displayed in Figure \dlo{\ref{fig:8}}\wen{\ref{fig:5}}, we deduce that both approaches can recover the signal. However, there is a remarkable difference in the amplitude in favor of our algorithm. It can be explained by the fact that DRR approach suppresses the residual noise at the entire frequency band to a relatively weak degree whereas our approach removes the residual noise sufficiently. That is why the amplitude spectrum of the proposed approach shown in Figure \dlo{\ref{Figure:8}(e)} \ref{Figure:5}(e) is perfect and very similar to that of the true data shown in Figure \dlo{\ref{Figure:8}(a)} \wen{\ref{Figure:5}(a)}. This analysis demonstrates one more time the better performance of the proposed algorithm compared to the DRR method. \wen{Therefore, we deduce that the proposed method can obtain successful results even though the observed noisy and incomplete data have very low amplitudes as shown in Figures \ref{Figure:5}(c)} \dlo{\ref{Figure:8}(c)}.}

Moreover, we conduct several numerical tests to compare the performances of both algorithms. The key idea of these experiments is to provide a practical guideline by quantifying the performance of both methods. They are implemented in terms of iterations number, \dlo{the} percentage of missing data, and \dlo{the}noise levels. Using the same observed noisy and incomplete 5D synthetic data corrupted by a noise level of $0.3$ and $70\%$ of missing traces, we \dlo{first} highlight the behavior of each method in terms of S/N \dlo{and RMSE}to the iteration numbers. \dlo{Figures \ref{Figure:11}(a) and \ref{fig:11}(b) show the S/N and rms error diagrams respectively, for}\wen{Figure \ref{fig:SNR_with_iterations} shows} the S/N \wen{values} for the iteration numbers \dlo{ranged}\wen{ranging} from $5$ to $30$. The blue and red lines indicate the S/N diagrams of the DRR method and the proposed approach, respectively. As shown on the figure\dlo{these figures}, it is visible that the proposed method surpasses the DRR method in terms of S/N\dlo{and RMSE}. \dlo{In both cases,}\wen{From this comparison, we find that} when the iteration number becomes large (approximately $25$), the S/N \wen{values} tends to decrease slightly.\dlo{Thus, the RMSE increases slowly.} We can therefore deduce from this analysis that both approaches behave the same way even though the proposed method is still better than the DRR method. From this comparison, which greatly highlights the accuracy of both methods concerning the iteration numbers, we can intuitively know the performance of each framework in terms of S/N \dlo{and RMSE}as the iteration number increase\wen{s}. 
\wen{From this figure, the best result from the proposed approach is at 15 iterations, whereas the best result from DRR is at 20 iterations. We find that the proposed method could save \old{$\frac{1}{4}$}\wen{25\%} of the computation\dlo{s} time, and \dlo{ten}\wen{10} \dlo{weight}\wen{weighted} POCS-like iterations can be used for the proposed method. Therefore, all examples in this paper are conducted with \dlo{ten}\wen{10} iterations.}

\inputdir{./}
\plot{SNR_with_iterations}{width=0.5\columnwidth}{Comparison of S/N diagrams regarding the iteration numbers. The blue and red lines correspond to the DRR and the proposed approaches, respectively. The performance of the proposed method is better than that of the DRR method as the iteration number increases. We decimated $70\%$ of traces and added a noise level of $0.3$ for this test.}

Then, we use $0.3$ as noise variance and we realize nine experiments with different decimated 5D synthetic data ranging from $10\% $ to $90\% $. Figure \dlo{\ref{Figure:12}(a)}\wen{\ref{fig:SNR_with_MissingTraces}\dlo{(a)}} \dlo{and (b) show respectively the SNR and RMSE}\wen{shows the S/N} diagrams with respect to the percentage of decimated data. At last, we randomly decimate $90\%$ of the 5D synthetic data and we conduct six tests using different noise levels 0.05, 0.2, 0.4, 0.6, 0.8 and 1. 
Figure \dlo{\ref{Figure:13}(a)}\wen{\ref{fig:SNR_with_noise_levels}\dlo{(b)} denotes}\dlo{present respectively,} the S/N \dlo{and RMSE}diagrams regarding noise levels. In both cases, the blue and red lines denote the diagrams of the restored data using the DRR approach and our method, respectively. As can be observed from the figures, our method performs better than the DRR method. When the percentage of decimated data becomes large, the distance between the DRR method and the RDRR method also becomes \dlo{imposing}\wen{more apparent}. Manifestly, when the noise variances increase, the \dlo{distance}\wen{difference} between both methods also decreases. However, the \dlo{distance}\wen{difference} between both diagrams is \dlo{still imposing}\wen{always evident.} From the diagrams presented, we deduce that our algorithm provides better results than the DRR method in terms of S/N\dlo{and RMSE}. Thus, the proposed RDRR method can be used to denoise 5D seismic data while reconstructing the missing values even in the conditions of a high degree of missing traces and strong random noise.

\inputdir{./}
\multiplot{2}{SNR_with_MissingTraces,SNR_with_noise_levels}{width=0.45\textwidth}{Comparison of S/N\dlo{(a) and RMSE (b)} diagrams after \dlo{ten}\wen{10} iterations between \dlo{both}\wen{two} algorithms. (a) S/N diagrams for the percentage of missing data. (b) S/N diagrams concerning the noise levels. In both cases, the blue and red lines correspond to the DRR and the proposed approaches, respectively. The red line still presents \dlo{the least RMSE} higher \wen{S/N values}. We used a noise variance of $0.3$, and then we decimated the traces from $10$ to $90\%$ for this demonstration.}

\wen{To corroborate the numerical tests, we display the results for only a single shot gather of each simultaneously denoised and reconstructed signal. The results are from an observed data contaminated by a noise level of $0.3$ and $80\%$ of missing data. Here, we select the following parameters to examine the performance of both algorithms: rank {$K$ = 6} and a \dlo{damped}\wen{damping} factor {$d$ = 2} for the DRR approach. In addition to these values, we use a cooling factor ${\beta = 3.3}$, a rational transfer function coefficient ${e = 0.95}$ and a window size ${T = 1}$ for the proposed algorithm. We run both methods using \dlo{ten}\wen{$10$} weighted POCS-like iterations. Figure \ref{fig:synth-clean-hxhy-s}\dlo{(a)} displays the true data. Figures \ref{fig:synth-noisy-hxhy-s}\dlo{(b)} and \ref{fig:synth-obs-hxhy-s}\dlo{(c)} denote the noisy data with S/N of $-5.38$ dB and observed noisy and incomplete data with S/N of $-1.74$ dB, respectively. Figures \ref{fig:synth-drr-hxhy-s}\dlo{(d)} and \ref{fig:synth-rdrr-hxhy-s}\dlo{(e)} display the results using the DRR method and the proposed method, respectively. The S/Ns are $10.40$ and $19.18$ dB for the DRR approach and the proposed approach, respectively. Figures \ref{fig:synth-drr-hxhy-s-e}\dlo{(a)} and \ref{fig:synth-rdrr-hxhy-s-e}\dlo{(b)} are the rms error \dlo{results}\wen{figures} of the DRR method and the proposed method, respectively. The useful signal is recovered with an rms error of $4.89\%$ and $1.56\%$ respectively for the DRR approach and our approach.} 


\inputdir{synth_linear_NV03_MT80}
\multiplot{5}{synth-clean-hxhy-s,synth-noisy-hxhy-s,synth-obs-hxhy-s,synth-drr-hxhy-s,synth-rdrr-hxhy-s}{width=0.30\textwidth}{Simultaneous reconstruction and denoising \wen{2D figures} comparison in only a single shot gather. (a) Clean data. (b) Noisy data with a variance of $0.3$. (c) Observed noisy with $80\%$ of missing traces. (d and e) Simultaneously denoised and reconstructed data using the DRR method the proposed approach, respectively.}

\inputdir{synth_linear_NV03_MT80}
\multiplot{2}{synth-drr-hxhy-s-e,synth-rdrr-hxhy-s-e}{width=0.35\textwidth}{Simultaneous reconstruction and denoising error \wen{2D figures} comparison of only one shot gather extracted from the 5D data matrix. (a) DRR approach with an rms error of $4.89\%$. (b) Proposed approach with an rms error of $1.56\%$.}

Figure \dlo{\ref{fig:17} and \ref{fig:19}}\wen{\ref{fig:synth-drr-hxhy-s0290,synth-rdrr-hxhy-s0290,synth-drr-xy-s0290,synth-rdrr-xy-s0290}} illustrates the numerical analysis\dlo{, respectively} in one common midpoint \dlo{($Nx_1$ = 6, $Nx_2$ = 6)}\wen{($x$ = 6, $y$ = 6)} and offset \dlo{($x_1$ = 6, $x_2$ = 6)}\wen{($hx$ = 6, $hy$ = 6)} gathers of each simultaneously denoised and reconstructed signal from \dlo{the}\wen{an} observed data corrupted by a noise variance of $0.2$ and $90\%$ of missing data. \wen{The S/N of this observed data $-0.23$ dB.} In these conditions, we use a rank {$K$ = 6} and a \dlo{damped}\wen{damping} factor {$d$ = 2} for the DRR approach. \dlo{In addition to}\wen{Based on} these parameters, we use a cooling factor ${\beta = 2.5}$, a rational transfer function coefficient ${e = 0.891}$ and a window size ${T= 1}$ for the proposed approach. We run both methods using \dlo{ten}\wen{$10$} weighted POCS-like iterations. Figures \ref{fig:synth-drr-hxhy-s0290}\dlo{(a)} and \ref{fig:synth-drr-hxhy-s0290}\dlo{(c)} display the results of the simultaneous denoising and reconstruction data via the DRR method. The S/N is approximately $5.20$ dB. Figures \wen{\ref{fig:synth-rdrr-hxhy-s0290}\dlo{(b)} and \ref{fig:synth-rdrr-hxhy-s0290}\dlo{(d)}} display the results using the proposed method. The S/N is about $17.84$ dB. \wen{The recovery error using each approach is displayed in Figure \ref{fig:synth-drr-hxhy-s-e0290,synth-rdrr-hxhy-s-e0290,synth-drr-xy-s-e0290,synth-rdrr-xy-s-e0290}. Figures \ref{fig:synth-drr-hxhy-s-e0290}\dlo{(a)} and \ref{fig:synth-drr-xy-s-e0290}\dlo{(c)} show the DRR approach with \wen{an} an rms error of $8.37\%$ and $8.82\%$ in one common-midpoint and one common-offset gather, respectively. Figures \ref{fig:synth-drr-hxhy-s-e0290}\dlo{(b)} and \ref{fig:synth-rdrr-xy-s-e0290}\dlo{(d)} are from the proposed approach with \wen{an} rms error of $2.63\%$ and $2.34\%$ in one common-midpoint and one common-offset gather, respectively. This comparison shows the superiority of the proposed algorithm when the observed data is severely decimated.}

\inputdir{synth_linear_NV02_MT90}
\multiplot{4}{synth-drr-hxhy-s0290,synth-rdrr-hxhy-s0290,synth-drr-xy-s0290,synth-rdrr-xy-s0290}{width=0.35\textwidth}{Simultaneous denoising and reconstruction \wen{2D figures} comparison between \dlo{both}\wen{two} approaches after \dlo{ten}\wen{10} iterations. (a and c) display the DRR approach in one common-midpoint and one common-offset gather, respectively. (b and d) display the proposed approach in one common-midpoint and one common-offset gather, respectively. We used an observed data corrupted by a noise variance of $0.2$ and $90\%$ of missing data for this example.}

\inputdir{synth_linear_NV02_MT90}
\multiplot{4}{synth-drr-hxhy-s-e0290,synth-rdrr-hxhy-s-e0290,synth-drr-xy-s-e0290,synth-rdrr-xy-s-e0290}{width=0.35\textwidth}{Simultaneous denoising and reconstruction error \wen{2D figures} comparison between both approaches after \dlo{ten}\wen{10} iterations. (a and c) display the DRR approach with an rms error of $8.37\%$ and $8.82\%$ in one common-midpoint and one common-offset gather, respectively. (b and d) display the proposed approach with an rms error of $2.63\%$ and $2.34\%$ in one common-midpoint and one common-offset gather, respectively.}

To further examine the performance of both approaches on a higher level of missing traces ($90\%$), we conduct a comparison using the periodogram power spectral density (PSD) of each corresponding 5D synthetic data mentioned in this last test. After a comparison of the different PSD diagrams shown in Figure \dlo{\ref{fig:21}}\wen{\ref{fig:Periodogrampsdcomparison9002}}, we find that the PSD of the restored data from our approach denoted in the red line and that of the true data shown in the green line are much closer to each other than the PSD of the DRR method indicated in \wen{the} the blue line. This comparison vividly \dlo{proves}\wen{demonstrates} that the proposed approach can yield the closest results to the original data\wen{,} even though we are in the conditions of a high level of missing traces.\\
Qualitative and quantitative analysis of these two illustrations conducted by using different noise variances and percentages of missing data further confirm the performance of the proposed approach in terms of accuracy. Note that, as the percentage of missing data increases, the proposed method becomes more accurate than the former approach.

\inputdir{./}
\plot{Periodogrampsdcomparison9002}{width=0.5\columnwidth}{Comparison of the periodogram power spectral density (PSD) of each 5D data set after \dlo{ten}\wen{10} iterations between both algorithms. The green line is from the clean data. The yellow line denotes the noisy data. The observed data is represented by the black line. The blue line corresponds to the DRR method. The red line is from the proposed method. The red and green lines are very close to each other in most areas.}

\wen{We then conduct another example to demonstrate the effectiveness of the proposed method on 5D synthetic data containing curved events. We compare the performances of the proposed approach to that of the DRR approach. We display the one common-midpoint gather comparison in Figure \ref{fig:hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0}. The clean data is displayed in Figure \ref{fig:hyper-clean2d-0}\dlo{(a)}. Figure \ref{fig:hyper-obs2d-0}\dlo{(b)} denotes the observed data with $80\%$ missing values and $0.2$ as noise variance. The significant events are difficult to see due to the percentage of missing traces and strong noise. By using a rank {$K = 12$} and a \dlo{damped}\wen{damping} factor {$d = 3$}, we denoise and reconstruct the observed data with the DRR approach. Based on these same values of $K$ and $d$, we apply our algorithm by using a ${\beta = 5}$, ${e = 0.954}$ and ${T = 1}$. We run both algorithms with \dlo{ten}\wen{$10$} POCS-like iterations. Figures \ref{fig:hyper-drr2d-0}\dlo{(c)} and \ref{fig:hyper-rdrr2d-0}\dlo{(d)} show the recovered data obtained using the DRR and the proposed approaches, respectively.} \wen{Compared to the DRR approach, our method performs much better results. As \dlo{reveals}\wen{revealed by} the comparison, the DRR result seems \wen{to} contain artifacts due to the presence of significant noise, which affects the quality of the useful signal. To see the difference in detail, we magnify a section of each corresponding data displayed in Figure \ref{fig:hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0}. The red\dlo{s} frame boxes indicate the magnified section plotted in Figure \ref{fig:hyper-z-clean,hyper-z-obs,hyper-z-drr,hyper-z-rdrr}. The Figures \ref{fig:hyper-z-clean}\dlo{(a)}-\ref{fig:hyper-z-rdrr}\dlo{(d)} correspond to the clean data, observed data, \dlo{recovered data}\wen{and data recovered} using the DRR and the proposed approaches, respectively.} 

\inputdir{synth_hyper}
\multiplot{4}{hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0}{width=1\textwidth}{\dlo{2-D figures c}\wen{C}omparison in one common-midpoint gather after \dlo{ten}\wen{10} iterations between \dlo{both}\wen{two} algorithms. (a) Clean data. (b) Observed noisy with $80\%$ of missing traces and $0.2$ as noise variance. (c and d) Simultaneously denoised and reconstructed data using the DRR method the proposed method, respectively.}


\inputdir{synth_hyper}
\multiplot{4}{hyper-z-clean,hyper-z-obs,hyper-z-drr,hyper-z-rdrr}{width=1\textwidth}{\dlo{{2-D figures c}}\wen{C}omparison of the magnified data displayed in Figure \ref{fig:hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0} (the red frame box). (a) Clean data. (b) Observed noisy with $80 \%$ of missing trace and $0.2$ as noise variance. (c and d) Simultaneously denoised and reconstructed data using the DRR and the proposed approaches, respectively.}

\wen{
	\dlo{Figures \ref{fig:17} and \ref{fig:18}}\wen{Figure \ref{fig:hyper-drr2d-e,hyper-rdrr2d-e} corresponds} to the error figure of each restored data displayed in Figure \ref{fig:hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0}. \dlo{and Figures \ref{fig:16}, respectively}\dlo{Figures \ref{fig:17}(a) and \ref{fig:18}(a) are}\wen{Figure \ref{fig:hyper-drr2d-e}\dlo{(a)} is from the DRR approach}. \dlo{Figures \ref{fig:17}(b) and \ref{fig:18}(b)}\wen{Figure \ref{fig:hyper-rdrr2d-e}\dlo{(b)} denotes the error figure} of the proposed algorithm. From Figures \ref{fig:hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0}\dlo{to Figure} \wen{to} \ref{fig:hyper-drr2d-e,hyper-rdrr2d-e}, we find that although the DRR algorithm removes noise and reconstructs the missing traces well, our approach still performs better results. From the magnified data comparison, which vividly \dlo{demonstrate}\wen{demonstrates} the superiority of our approach, we find that the restored data obtained using our approach is much similar to the clean data than those of the DRR result. The visual examination of each subfigure shows that the proposed method offers better simultaneously denoised and reconstructed data. From the fewer errors that \dlo{provides}the proposed algorithm \wen{provides}, we deduce that the recovered data has the smallest amount of artifacts. In this example, the S/N values of the observed data, the recovered data using the DRR method, and the proposed method are {$0.58$}, {$10.94$}, and {$18.43$ dB}, respectively. The DRR approach and the proposed approach achieve the simultaneous denoising and reconstruction process with rms error values $9.07\%$ and $3.08\%$, respectively. Based on the numerical analysis, it is evident that the proposed algorithm can produce higher S/N values, consequently\wen{,} lower rms error values, and thus, the recovered data can be much \dlo{similar}\dlo{related}\wen{closer} to the clean data. We deduce that our algorithm can introduce fewer artifacts. The visual examination and the numerical test comparison demonstrate the recovery improvement of our algorithm on curved events.}

\inputdir{synth_hyper}
\multiplot{4}{hyper-drr2d-e,hyper-rdrr2d-e}{width=1\textwidth}{Simultaneous denoising and reconstruction error comparison in common-midpoint gather. \dlo{(a) Simultaneously denoised and reconstructed errors using the DRR method with an rms error of $9.07\%$. (a) Simultaneously denoised and reconstructed errors using the proposed method with an rms error of $3.08\%$.}\wen{(a) \dlo{shows the 2-D figures of t}\wen{T}he error using the DRR method with an rms error of $9.07\%$. (b) \dlo{displays the 2D figures of t}\wen{T}he error using the proposed method with an rms error of $3.08\%$.}}

\wen{
	To demonstrate the performance of the proposed approach in other perspective\wen{s}, we display in Figure \dlo{\ref{Figure:19}}\wen{\ref{fig:fx_clean_curved,fx_Observed_curved,fx_DRR_curved,fx_Proposed_curved}}, the corresponding f-x spectra of each data shown in Figure \dlo{\ref{fig:16}}\wen{\ref{fig:hyper-clean2d-0,hyper-obs2d-0,hyper-drr2d-0,hyper-rdrr2d-0}}. The \dlo{sub-figures \dlo{\ref{fig:19}(a)-\ref{fig:19}(d)}\wen{\ref{fig:15}(a)-\ref{fig:15}(d)}}Figures \wen{\ref{fig:fx_clean_curved}-\ref{fig:fx_Proposed_curved}} correspond to the f-x spectra of the clean data, the observed data, the restored data using the DRR and the proposed approaches, respectively. From the comparison of each subfigure, we find that both approaches can successfully denoise and reconstruct the missing values in the whole frequency band (from $0$ \new{Hz} to $125$ Hz). However, a detailed comparison highlights the greatest difference between both approaches. Indeed, based on the lower frequencies (from $0$ \wen{Hz} to approximately $40$ Hz), we can affirm that our algorithm further \dlo{remove}\wen{removes} the noise energy to a weaker degree and improves the signal quality compared with the DRR algorithm, which shows the better quality of the recovered results using our algorithm. From this analysis, we can intuitively deduce that our approach can successfully remove the random noise while reconstructing the useful signal more adequately than the DRR approach.}		

\inputdir{./}
\multiplot{4}{fx_clean_curved,fx_Observed_curved,fx_DRR_curved,fx_Proposed_curved}{width=0.35\textwidth}{\dlo{One single shot gathers}Frequency-space (f-x) spectra comparison after \dlo{ten}\wen{10} iterations between \dlo{both}\wen{two} algorithms. (a and b) The clean data and observed data, respectively. (c and d) The DRR approach and the proposed framework, respectively.}

\wen{In the presence of random noise and missing traces, we evaluate the quality of the simultaneously denoised and reconstructed data using both approaches after \dlo{ten}\wen{$10$} iterations. We fix the noise variance at $0.2$ while varying the missing traces from $10\%$ to $90\%$, and we measure the S/N values. Figure \dlo{\ref{Figure:21}}\wen{\ref{fig:snr_missing_traces_curvedD}} shows the S/N values as functions of missing traces. From this figure \dlo{above mentioned}\wen{mentioned above}, it is undeniable that as the percentage of missing trace becomes large, the proposed method (the red line) consistently provides higher values of S/N than the DRR approach (the blue line). For both approaches, the simultaneous denoising and reconstruction quality decreases as the percentage of missing traces \dlo{increase}\wen{increases}. However, our algorithm can provide \wen{a} satisfactory result\wen{,} even though the observed data is corrupted with a significant ratio of missing traces and noise levels. These numerical and visual \dlo{analyses}\wen{analyses} further confirm the adaptability of our approach \dlo{on}\wen{to} data containing curved events. 
}

\inputdir{./}
\plot{snr_missing_traces_curvedD}{width=0.5\columnwidth}{Comparison of S/N diagrams for the percentage of missing data after \dlo{ten}\wen{10} iterations between \dlo{both}\wen{two} algorithms on data containing curved events. The blue and red lines correspond to the DRR method and the proposed approach, respectively. The red line still presents higher S/N values. We used a noise variance of $0.2$ and then decimated the traces from $10$ to $90\%$ for this comparison.}

In order to evaluate the computing time, we test the efficiency of each approach on different 5D synthetic data sizes after \dlo{ten}\wen{10} iterations and a frequency band \wen{of} $0$-$100$ Hz. The comparison of the running time is shown in Table \ref{tbl:table1}. \dlo{Let us mention that b}\wen{B}oth algorithms have been performed on an Intel Core i7 7th generation running MATLAB codes (R2017a). From this comparison, we can note a \dlo{small}\wen{little} bit of difference between both approaches in favor of our method. Because of this relatively less difference, we deduce that the computation time of these methods is almost the same. However, we find that as the size of the matrix increases, the computation time also increases for both approaches. The same is true for the number of iterations and the frequency.

\subsection{Field data examples}
To verify the performance of our approach in practice, we apply both algorithms on a 5D field seismic data. Here, we have considered a visual examination of the results obtained via both methods to demonstrate the performances of our algorithm.
%\dlo{Figures \ref{Figure:23}, \ref{Figure:24} and \ref{Figure:25} display the comparison in one common midpoint gather, one common offset gather and 500 traces, respectively. Figures \ref{Figure:23}(a), \ref{Figure:24}(a) and \ref{Figure:25}(a) show the observed noisy and incomplete data. In this example, about 75\% of traces are missing. To preserve the significant features of the useful signal, we select rank {$K= 6$} and damping factor {$d = 2$} for the DRR approach. Figures \ref{Figure:23}(b), \ref{Figure:24}(b) and \ref{Figure:25}(b) present the results of this approach. The DRR method obtains successful results. Indeed, the recovery of the missing data is perfect. However, coherent events cannot be seen clearly due to the presence of residual noise in the results. In addition to the same parameters used for the DRR method, we use a cooling factor $\beta= 3$, a rational transfer function coefficient ${e= 0.9}$ and a window size ${T= 1}$ for the proposed method. We run both programs using 10 weighted {POCS-like} iterations. As can be seen in Figures \ref{Figure:23}(c), \ref{Figure:24}(c) and \ref{Figure:25}(c), which display the results obtained by the proposed approach, all useful signal\wen{s} \dlo{is}\wen{are} perfectly recovered. All significant events are highlighted and can be perceived without much effort on each sub-figures mentioned. To better compare them in detail, we zoom a portion from each sub-figure in Figure \ref{Figure:25} and display the comparison in Figure \ref{Figure:26}. The red frame boxes are shown in Figure \ref{Figure:25} to highlight the zoomed data. After a comparison of the Figures \ref{Figure:26}(a-c), it is obvious that our method provides better results than those of the DRR approach. The zoomed data comparison further demonstrates the accuracy of our algorithm.}
\wen{Figures \dlo{\ref{fig:22} and \ref{fig:23}}\wen{\ref{fig:cmp_field_obseerved,cmp_field_DRR,cmp_field_proposed} and \ref{fig:offset_field_obseerved,offset_field_DRR,offset_field_Proposed}} display the comparison in one common-midpoint and one common-offset gather, respectively. Figures \dlo{\ref{fig:22}}\wen{\ref{fig:cmp_field_obseerved}}\dlo{(a)} and \dlo{\ref{fig:23}}\wen{\ref{fig:offset_field_obseerved}}\dlo{(a)} show the observed noisy and incomplete data. In this example, approximately $75\%$ of traces are missing. To preserve the significant features of the useful signal, we select rank {$K= 6$} and damping factor {$d = 2$} for the DRR approach. Figures \dlo{\ref{fig:22}}\wen{\ref{fig:cmp_field_DRR}}\dlo{(b)} and \dlo{\ref{fig:23}}\wen{\ref{fig:offset_field_DRR}}\dlo{(b)} show the results\dlo{of this approach}. The DRR method obtains successful results. Indeed, the recovery of the missing data is \old{perfect}\wen{better}. However, coherent events cannot be seen clearly \dlo{due to the presence of}because of residual noise in the results. In addition to the same parameters used for the DRR method, we use a cooling factor $\beta= 3$, a rational transfer function coefficient ${e= 0.9}$, and a window size ${T= 1}$ for the proposed method.} We run both \dlo{programs}\wen{algorithms} using \dlo{ten}\wen{10} weighted {POCS-like} iterations. As can be seen in Figures \dlo{\ref{fig:22}}\wen{\ref{fig:cmp_field_proposed}}\dlo{(c)} and \dlo{\ref{fig:23}}\wen{\ref{fig:offset_field_Proposed}}\dlo{(c)}, which display the results obtained by the proposed approach, all useful signal\wen{s} \dlo{is}\wen{are} perfectly recovered. \dlo{All}\wen{The} significant events are highlighted and can be perceived without much effort on each subfigure\dlo{mentioned}. \wen{For further comparison, we display in Figures \dlo{\ref{fig:24}(a)-\ref{fig:24}(c)}\wen{\ref{fig:Zoomed_offset_field_obseerved}\dlo{(a)}-\ref{fig:Zoomed_offset_field_Proposed}\dlo{(c)}}, the magnified section of each subfigure \dlo{\ref{fig:23}(a)-\ref{fig:23}(c)}\wen{\ref{fig:offset_field_obseerved}\dlo{(a)}-\ref{fig:offset_field_Proposed}\dlo{(c)}}, which are highlighted by the green frame boxes, respectively. The magnified data reveals \dlo{the presence of}\wen{some} curved events in one common offset gather. We can therefore deduce that although the field data \dlo{is}\wen{are} mainly composed of linear events, it is also \dlo{consist}\wen{consisted} of curved events in some sections. From\dlo{,} the magnified data comparison, it is obvious that the proposed method provides better results than \dlo{those of}the DRR method. The magnified data comparison further demonstrates the accuracy of our algorithm.} 

\dlo{On the other hand, we compare both methods using the corresponding f-x spectrum and normalized PSD of the 500 traces of aforementioned data. Figures \ref{Figure:27} and \ref{Figure:28} display the f-x spectrum and normalized PSD, respectively. In Figure \ref{Figure:27}, (a) denotes the f-x spectrum of the observed noisy and incomplete data. (b) is from the DRR approach and (c) corresponds to the f-x spectrum of the proposed approach. The yellow, blue and red lines shown in Figure \ref{Figure:28} are the normalized PSD of the decimated data, the restored data from the DRR algorithm and our approach, respectively.}

\inputdir{./}
\multiplot{3}{cmp_field_obseerved,cmp_field_DRR,cmp_field_proposed}{width=0.30\textwidth}{Common midpoint gather \wen{2D figures} comparison. (a) Observed noisy and incomplete data with about $75\%$ of missing traces. (b and c) denote the simultaneously denoised and reconstructed data using the DRR approach and the proposed approach, respectively.}

\inputdir{./}
\multiplot{3}{offset_field_obseerved,offset_field_DRR,offset_field_Proposed}{width=0.29\textwidth}{Common-offset gather \wen{2D figures} comparison. (a) Observed noisy and incomplete data with approximately $75\%$ of missing traces. (b and c) The simultaneously denoised and reconstructed data using the DRR approach and the proposed approach, respectively.}

\inputdir{./}
\multiplot{4}{Zoomed_offset_field_obseerved,Zoomed_offset_field_DRR,Zoomed_offset_field_Proposed}{width=0.29\textwidth}{Magnified section from Figure \ref{fig:offset_field_obseerved,offset_field_DRR,offset_field_Proposed} (the green frame boxes) comparison. (a) Observed noisy and incomplete data with approximately $75\% $ of missing traces. (b and c) The simultaneously denoised and reconstructed data using the DRR method and the proposed approach, respectively.}
		 
\wen{
	Moreover, we compare both methods using the corresponding f-x spectrum of each data displayed in Figure \dlo{\ref{fig:23}}\wen{\ref{fig:offset_field_obseerved,offset_field_DRR,offset_field_Proposed}}. \dlo{In Figure \dlo{\ref{fig:25}, \ref{fig:25}(a)}\wen{\ref{fig:20}},}\wen{Figure \ref{fig:fx_offset_obs_field}-\ref{fig:fx_offset_Proposed_field}}\dlo{\ref{fig:20}} denotes the f-x \dlo{spectrum}\wen{spectra} of the observed noisy and incomplete data\dlo{. \dlo{\ref{fig:25}}\dlo{\ref{fig:20}}(b) is from}\wen{,} the DRR approach, and \dlo{\dlo{\ref{fig:25}}\dlo{\ref{fig:20}}(c) corresponds to the f-x spectrum of}the proposed approach, \wen{respectively}. Analysis of the f-x spectra \dlo{better proves}\wen{further shows} that random noise included in the decimated data cannot be completely attenuated by only using the damping operator. From the comparison, we find that our method can yield \dlo{perfect}\wen{better} results than the DRR approach. It is visible that the proposed approach can improve the quality of the useful signal \dlo{due to}\wen{because of} the energy of the events. We can deduce that the simultaneous denoising and reconstruction errors of the proposed approach are \dlo{very}\wen{much} smaller than that of the DRR method. The f-x spectra comparison further verifies the better reconstruction quality of our algorithm. From Figure \dlo{\ref{fig:25}}\wen{\ref{fig:fx_offset_obs_field,fx_offset_DRR_field,fx_offset_Proposed_field}}, we deduce that the proposed approach can provide a higher resolution than the DRR method.}

\inputdir{./}
\multiplot{3}{fx_offset_obs_field,fx_offset_DRR_field,fx_offset_Proposed_field}{width=0.30\textwidth}{Frequency-space (f-x) spectra comparison of each data displayed in Figure \dlo{\ref{fig:23}}\wen{\ref{fig:offset_field_obseerved,offset_field_DRR,offset_field_Proposed}}. (a) The f-x spectra of the decimated data. (b and c) The f-x spectra obtained after using the DRR and the proposed approaches, respectively.}

\section{discussion}

This paper investigates the feasibility of the RDRR method \dlo{developed herein}for simultaneous denoising and reconstruction of 5D seismic data. The damping operator, which is one of the key\dlo{s} parameters of the DRR framework, has been introduced into the conventional TSVD formula to further suppress random noise. However, we find that \dlo{using only}\wen{only using} this operator is not enough to recover the useful signal when the percentage of missing traces \wen{and the noise level} \dlo{become}\wen{becomes} large. Hence, how to accurately restore the useful signal \dlo{pays our attention}\wen{becomes our focus}. \dlo{One of the contributions}\wen{The contribution} of this work is the development of the STMA into the existing DRR framework. The proposed algorithm \dlo{that}aims at designing an ideal combination of STMA operator and DRR formula to further enhance the recovery of the useful signal\wen{s}. \dlo{, can \dlo{benefit from} the individual advantage of each operator.}Acceleration of computation time usually \dlo{pays}\wen{attracts} attention \dlo{of}\dlo{to}\wen{from} most researchers when using the low-rank method for seismic data simultaneous denoising and reconstruction. Here, by introducing the STMA operator into the DRR formula, we focus not only on enhancing the computation cost but also \wen{on} random noise removal.

The tight connection established between the STMA operator and the DRR formula compensates for the DRR method. Thus, the RDRR formula can be regarded as an improved DRR formula, which further removes the residual noise and recovers the useful signal. 

\wen{Our RDRR framework}\dlo{We understand these clarifications as the physical definition of our robust damped rank-reduction framework, which} uses five keys parameters: rank $K$, damping factor $d$, cooling factor $\beta$ that is used to control the effects of the thresholding parameter $\tau$, the rational transfer function coefficient $e$ and window size $T$. These parameters used in our proposed framework are essential to achieve the \dlo{ultimate}goal of this work. The empirical selection of these five useful parameters usually leads to satisfactory results. 

\wen{The proposed RDRR method was implemented by varying $K$, $d$, $\beta$, $e$ and $T$, and the resulting \dlo{SNRs}\wen{S/N} and rms error values were selected as the quantitative measures to \dlo{analysis}\wen{analyze} their influence on the simultaneous denoising and reconstruction performance. In this section, we use the first \dlo{example of synthetic data}\wen{synthetic example} to show the influence of each parameter on the proposed algorithm performance. The parameters $K$, $d$, $\beta$, $e$ and $T$ were set at $6$, $2$, $3.3$, $0.972$ and $1$, respectively to simultaneous denoise and reconstruct observed data corrupted by $0.3$ as noise variance and $70\%$ of missing traces. Figure \wen{\ref{fig:snr_with_K}}\dlo{(a)} shows the influence of $K$ for different values.\dlo{We vary the values of $K$ from $1$ to $10$ while fixing the other parameters to see its influence.} As seen from this subfigure, a $K$ value of $6$ produces a better result in terms of S/N. Thus, we adopted this value of rank to restore the useful signal. Besides, as \dlo{can be seen}observed in Figure \wen{\ref{fig:snr_with_d}}\dlo{(b)}, it is \dlo{explicit}\wen{clear} that \dlo{the damping factor}$d=2$ can positively affect the result. \dlo{we range the damping factor from $1$ to $3$, and plot the results in Figure \ref{fig:26}. From this figure, it is explicit that $d=2$ can positively affect the result.}From Figure \ref{fig:snr_with_beta}\dlo{(c)}, \dlo{it is clear that}$\beta$ of $3$ can produce the best S/N value. Therefore, by adjusting this parameter properly, we adopted \dlo{$\beta$ of $3.3$}\wen{$\beta = 3.3$} to recover the useful signal in this example. \dlo{Then, we change the cooling factor from $1$ to $10$ to see its influence on this result. Figure \ref{fig:26}\dlo{(c)}\wen{c} shows the results. From this figure, $\beta$ of $3$ can produce the best S/N value. Therefore, by adjusting this parameter properly, we adopted $\beta$ of $3.3$ to recover the useful signal in this example. In the same way, we analyze the effect of $e$ by ranging its values from 0.95, 0.96,..., to $1$. As shown in Figure \ref{fig:26}}As shown in Figure \wen{\ref{fig:snr_with_e}}\dlo{(d)}, the best quality of the signal can be provided by fixing $e$ to approximately $0.97$. So, by regulating the parameter accurately, we used $e=0.972$ to recover the useful signal.\dlo{Finally, as displayed in the sub-figure \ref{fig:26} we range the parameter $T$ from $ 1 $ to $ 5 $ to analyze its behavior. The analysis of this diagram demonstrates}\dlo{.} Finally, as displayed in the \dlo{sub-figure}\wen{Figure} \wen{\ref{fig:snr_with_T}}\dlo{(e)}, all values of $T$ set above $1$ produce lower S/N values. Thus, we selected $T$ of $1$ to restore the useful signal. From this analysis, we can \dlo{appreciate}\wen{understand} the contribution of each parameter to the quality of our results.} \wen{The parameter $e$ is \dlo{a} helpful \dlo{tool} to enhance the energy of the useful signal when the best trade-off with the parameter $T$ is reached.}

\inputdir{./}
\multiplot{5}{snr_with_K,snr_with_d,snr_with_beta,snr_with_e,snr_with_T}{width=0.3\textwidth}{Influence of the five key parameters under a noise variance of $0.3$ and $70\%$ as missing traces after $10$ iterations. (a) The influence of the rank constraint. (b) The influence of the damping factor. (c) The influence of the cooling factor. (d) The influence of the rational transfer function coefficient. (e) The effect of the window size.}

\wen{The proposed approach uses \dlo{many}\wen{several} operators to recover the useful signal from the noisy observation. It is therefore necessary to show their influence on the quality of our results. By using the same observed data \dlo{above mentioned}\wen{mentioned above}, we first show the performance of the ST operator, the MA operator, the STMA operator, and the RR operator on the level-4 block Hankel matrix. The S/N of the observed data is $-2.40$ dB. In Figure \dlo{\ref{fig:27}}\wen{\ref{fig:influence_operator_block_HMatrice}}, we plot the S/N\dlo{s} values as a function of iteration numbers ranging from $5$ to $30$.}
\wen{The black, gray, gray dashed, and blue lines correspond to the RR, STMA, MA, and ST operators, respectively. From this figure, we find that the ST operator fails to simultaneously denoise and reconstruct the missing traces whatever the value of the cooling factor used to adjust the threshold parameter. The influence of ST on the level-4 block Hankel is almost insignificant because it provides very low S/N. In contrast, the MA operator can recover the useful signal from the level-4 block Hankel matrix because the S/N\dlo{s} values (Figure \dlo{\ref{fig:27}}\wen{\ref{fig:influence_operator_block_HMatrice}}) are quite acceptable. Note that, when we set $T$ at $2$, and we use the smaller values of $e$ ($e= 0.1,...,0.7$), we cannot obtain acceptable results. The results become acceptable at approximately $e=0.9$. All values of $e$ selected above $1$ damage the features of the useful signal. \dlo{The the amplitude of the signal can be degraded.}}\wen{Besides, when we fix $e$ at $0.99$ while using a small value of window size (e.g., $T=2$), the MA operator cannot \dlo{adequately simultaneous}\wen{effectively} denoise and reconstruct the missing values when it is directly applied to the level-4 block Hankel matrix. The approximation signal contains an important quantity of noise, whereas large values can recover the useful signal from its noisy observation. However, the recovered data lose an important amount of \dlo{data}\wen{signals} in one common midpoint gather. The results in \dlo{one}\wen{the} common-offset gather are \dlo{generally quite}acceptable.}
\wen{As shown in Figure \dlo{\ref{fig:27}}\wen{\ref{fig:influence_operator_block_HMatrice}}, the S/N \dlo{diagram}\wen{values} using the STMA operator \dlo{outperforms}\wen{are higher than} both the ST and MA \wen{S/N} values. We deduce that by combining the ST and the MA operators (STMA), we can \dlo{profit to}\wen{benefit from} their individual performance and thus further influence the level-4 block Hankel matrix. In Figure \dlo{\ref{Figure:28}}\wen{\ref{fig:synth-hxhy-s-stma1,synth-hxhy-s-stma2,synth-xy-s-stma1,synth-xy-s-stma2}}, we plot the STMA results first, for $\mathbf{\beta}=80$, $e=0.999$, $T=2$, and then, $\mathbf{\beta}=15$, $e=0.999$, $T=17$. Figures \dlo{\ref{fig:28}(a) and \ref{fig:28}(c) and Figures \ref{fig:28}\dlo{(b)}\new{b} and \ref{fig:28}\dlo{(d)}\wen{d}} \wen{\ref{fig:synth-hxhy-s-stma1}\dlo{(a)} and \ref{fig:synth-xy-s-stma1}\old{(c)} and Figures \ref{fig:synth-hxhy-s-stma2}\dlo{(b)} and \ref{fig:synth-xy-s-stma2}\old{(d)}} show the results using both cases, respectively. The first case yields \wen{S/N =$4.07$} dB \dlo{as SNR}while the second situation \dlo{performs with $10.46$ dB}\wen{S/N = $8.00$} dB after $15$ iterations. From this comparison, we find that when applying the STMA operator directly on the level-4 block Hankel matrix, the larger values of $T$ can provide higher values in terms of S/N. However, the smoothing \dlo{degree} damages the useful signal in one common-midpoint gather (Figure \dlo{\ref{fig:28}}\wen{\ref{fig:synth-hxhy-s-stma2}}\dlo{(b)}). \dlo{Whereas}\wen{However}, the \dlo{one} common-offset gather result (Figure \dlo{\ref{fig:28}}\wen{\ref{fig:synth-xy-s-stma2}}\dlo{(d)}) is satisfactory. From this test, we find that the influence of the ST operator can be seen when it is combined with the MA operator.} \wen{From Figure \dlo{\ref{fig:27}}\ref{fig:influence_operator_block_HMatrice}, the RR operator demonstrates its superiority over the ST, MA, and STMA operators with \wen{a} rank \wen{of} six. From the different tests, we find that for $T=1$, the STMA operator provides the same result as the ST operator whatever the combination of the parameters when it is directly applied to the level-4 block Hankel matrix to recover the useful signal. STMA can simultaneous\new{ly} denoise and reconstruct the level-4 block Hankel matrix when $T>1$. However, all values of $T$ selected above $1$ induce some loss of data in one common-midpoint gather. From our experience, we find that STMA is not adequate to preserve all features of the useful signal when it is directly applied to the block Hankel matrix\wen{.}\dlo{ to denoise and reconstruct the missing traces.} STMA can be introduced in an existing algorithm of denoising and/or reconstruction to improve its performance.} 

\inputdir{./}
\plot{influence_operator_block_HMatrice}{width=0.5\columnwidth}{Influence of the operators (ST, MA, STMA, and RR) on the level-4 block Hankel matrix under a noise variance of $0.3$ and $70\%$ as missing traces after \dlo{ten}\wen{$10$} iterations. The blue line corresponds to the ST operator. The dashed and solid gray lines are from the MA and STMA operators, respectively. The black line denotes the RR operator.}

\inputdir{synth_stma_block_Hankel_matrix}
\multiplot{4}{synth-hxhy-s-stma1,synth-hxhy-s-stma2,synth-xy-s-stma1,synth-xy-s-stma2}{width=0.35\textwidth}{Influence of the STMA operator on the level-4 block Hankel matrix. (a and c) The one common-midpoint and and common-offset gather\dlo{2-D figures}, respectively, for \wen{$\mathbf{\beta}=80$, $e=0.999$, $T=2$}. (b and d) The one common-midpoint and common-offset gather, respectively, for \wen{$\mathbf{\beta}=15$, $e=0.999$, \wen{and} $T=17$.}}

\wen{To verify the adaptability of the STMA operator with some iterative denoising and reconstruction methods, we introduce the proposed STMA operator in the damped data-driven optimal singular value shrinkage algorithm \citep{siahsar2017simultaneous} framework for simultaneous denoising and interpolation of 3D seismic. Here, STMA is first applied to the block Hankel matrix before SVD, and then, to the singular values just after the SVD. For this test, we add a noise variance of $0.2$ to the 3D synthetic data and we decimate $50\%$. The S/N of the noisy data and the observed data is approximately $-8.40$ dB and $-5.98$ dB, respectively. Figures \dlo{\ref{Figure:29} and \ref{fig:30}}\wen{\ref{fig:syn3d-c-s,syn3d-n-s,syn3d-obs-s,syn3d-opshrinkdamped-s,syn3d-opshrinkdampedstma-s}}\dlo{and \ref{fig:25}} show the 2D slice comparison in the 5th crossline\dlo{ and inline sections, respectively}. Figures \dlo{\ref{fig:29}(a)-\ref{fig:29}(c)}\wen{\ref{fig:syn3d-c-s}\dlo{(a)}-\ref{fig:syn3d-obs-s}\dlo{(c)}} correspond to the clean data, noisy data, and observed data, respectively. Figures \dlo{\ref{fig:30}(d) and \ref{fig:30}(e)}\wen{\ref{fig:syn3d-opshrinkdamped-s}\dlo{(d)} and \ref{fig:syn3d-opshrinkdampedstma-s}\dlo{(e)}} display the recovered data using the damped data-driven optimal singular value shrinkage (damped optshrink) algorithm\wen{,} and the modified damped data-driven optimal singular value shrinkage algorithm, respectively. From the comparison of each sub-figure mentioned, the modified algorithm can obtain better recovery performance.\dlo{(Figures \ref{fig:29}(e) and \ref{fig:30})} The result of the modified algorithm is obtained with  $K=3$, $d=2$, $\mathbf{\beta}=2.10$, $e=0.991$, and $T=1$. The S/Ns are $7.77$ dB and $8.22$ dB for the damped data-driven optimal singular value shrinkage algorithm\wen{,} and the modified algorithm, respectively. We also analyze the contribution of the STMA operator by conducting two \dlo{significant}\wen{meaningful} numerical tests. First, by considering the S/N values as a function of iteration numbers. For this experiment, we range the iteration numbers from $5$ to $30$, and we plot the results in Figure \dlo{\ref{fig:31}}\wen{\ref{fig:snr_IterationN_DampedOpshrinkSTMA}}\dlo{(a)}. Then, we fix the noise level at $0.2$ and we vary the missing traces from $10\%$ to $90\%$. We \dlo{displays}\wen{display} the performance of each approach for the percentage of missing data in Figure \dlo{\ref{Figure:31}}\wen{\ref{fig:snr_missing_trace_DampedOpshrink_stma}}\dlo{(b)}. From both subfigures, we find that the STMA operator can effectively improve the damped data-driven optimal singular value shrinkage algorithm.} 

\inputdir{optshrink_damped_stma}
\multiplot{5}{syn3d-c-s,syn3d-n-s,syn3d-obs-s,syn3d-opshrinkdamped-s,syn3d-opshrinkdampedstma-s}{width=0.3\textwidth}{\dlo{Single slice comparison (5th crossline slice). (a-c) Clean, noisy, and observed data, respectively. (d and e) Recovered.} \wen{Single slice 2D figures comparison (fifth crossline slice). (a) Clean data. (b) Noisy data. (c) Observed data. (d and e) The recovered data obtained using the damped data-driven optimal singular value shrinkage algorithm and the modified algorithm, respectively.}}

\inputdir{./}
\multiplot{2}{snr_IterationN_DampedOpshrinkSTMA,snr_missing_trace_DampedOpshrink_stma}{width=0.35\textwidth}{S/N diagrams comparison between two approaches.\dlo{a noise level $0.2$ and $50\%$ as missing traces} (a) S/N\dlo{s} values for iteration numbers. (b) S/N\dlo{s} values as a function of missing traces after $15$ iterations. In both cases, the gray and black lines are from the damped data-driven optimal singular value shrinkage algorithm, and the modified algorithm, respectively.}

\wen{Then, to show the \wen{individual} contribution of each operator that uses our approach, we conducted the following combination: the RR and ST operators (RR + ST), the RR and MA operators (RR + MA), the RR operator and the damping factor (DRR method), the RR and STMA operators (RR + ST + MA), the DRR and ST operators (RR + damping + ST), the DRR and MA operators (RR + damping + MA), and the DRR and STMA operators (RR + damping + ST + MA, which corresponds to the proposed approach)\wen{.}\dlo{combine first, the RR and ST operators (RR + ST) in the same framework to see the effect of ST. Then, we mix the RR and MA operators (RR + MA) to see the performance of MA. Afterward; we introduce the damping factor into the conventional RR framework (RR + damping factor, which corresponds to the DRR method), to show the influence of the damping factor. In the same way, we remove the damping factor, and; we connect the STMA operator, to see the contribution of STMA. Besides, we remove the MA function from the proposed approach (RDRR), to analyze the result using the DRR with ST (DRR + ST). Similarly, we drop the ST and keep the DRR associated with the MA function (DRR + MA), to analyze the effect. Finally, the DRR and STMA operators (RR + damping factor + ST + MA, which corresponds to the proposed approach) are connected into the same framework to simultaneous denoise and reconstruct the missing trace.} Based on these experiments, the proposed approach can be regarded as a combination of the RR, damping, ST, and MA operators. We apply these mixed operators on the synthetic data of our first example (5D synthetic data having linear events corrupted by $ 0.3 $ as noise variance and $70 \% $ of missing traces). Because of the best quality of the result, we adopted rank 6 for the RR approach. We select $K=6$ and $\mathbf{\beta}=0$, for RR + ST, and $K=6$, ${d}=2$, $\mathbf{\beta}=0$, for RR + damping + ST. In both cases, we have adopted $\mathbf{\beta}=0$ because all values of $\mathbf{\beta}$ selected below or above $0$ influence negatively the S/N and hence affect the quality of the result. To restore the useful signal via RR + MA, we selected $K=6$, $e=0.982$, and $T=1$. For RR + ST + MA, we set $K$, $\mathbf{\beta}$, $T$, $e$ and  at $6$, $30$, $1$, and $0.964$, respectively. The parameters used by RR + damping + MA were set at $K=6$, $d=2$, $e=0.975$ and $T=1$. For the proposed approach (RR + damping + ST + MA), we selected $K=6$, $d=2$, $\mathbf{\beta}=3.3$, $e=0.972$ and $T=1$. We run all approaches with \dlo{ten}\wen{10} iterations. As can be seen, when STMA is \dlo{joined to}\wen{combined with} the RR or DRR approaches, we need to select the cooling factor $\mathbf{\beta} > 0$ to adjust the threshold parameter $\tau$. We deduce that the three parameters ($e$, $T$, and $\mathbf{\beta}$) that STMA uses are not negligible to achieve the goal of the proposed method. Table \ref{tbl:table2} displays the S/N values obtained by each operator and mixed operators after \old{ten}\wen{10} iterations. From the comparison of S/N\dlo{s} values, we find that only the ST operator is not able to improve the RR and DRR algorithm. Indeed, the results are almost the same. However, it is clear that only using the MA operator can improve the RR and the DRR algorithm. When we remove the damping factor from the proposed algorithm (RDRR), it corresponds to the RR + ST + MA approach. From Figures \dlo{\ref{fig:29}(b) and \ref{fig:32}(b)}\wen{\ref{fig:synth-rrstma-s}\dlo{(b)} and \ref{fig:synth-rrstma-xy-e-s}\old{(b)}}, we find that the introduced STMA function into the RR method framework after the TSVD process can \dlo{greatly}\wen{successfully} improve the result of the simultaneous denoising and reconstruction of 5D data. Compared to the damping operator (Figure \dlo{\ref{fig:31}(a) and \ref{fig:32}(a)}\wen{\ref{fig:synth-rrdamping-s}\old{(a)} and \ref{fig:synth-rrdamping-xy-e-s}\dlo{(a)}}), we find that RR + ST + MA operators can better reconstruct the missing traces than RR + damping operators. However, based on the visual comparison, the RR + damping operators can perfectly remove the residual noise from the noisy observation than the RR + ST + MA operators. Therefore, by introducing the damping and the STMA operators in the RR framework, we can greatly denoise while reconstructing the noisy and missing data from the noisy level-4 block Hankel matrix. Figures \dlo{\ref{fig:31}(e) and \ref{fig:32}(e)}\wen{\ref{fig:synth-rrdampingstma-s}\dlo{(e)} and \ref{fig:synth-rrdampingstma-xy-e-s}\dlo{(e)}} show the results obtained by combining the RR, damping and STMA operators. 
	
We also analyze the influence of each approach by evaluating the S/N\dlo{s} values for iterations numbers (varying from $ 5 $ to $ 30 $). Figure \dlo{\ref{fig:30}}\wen{\ref{fig:Contribution_of_each_operator}} shows the S/N\dlo{s} diagrams obtained using the RR operator (the yellow line), RR + MA operator (the green line), RR + STMA operators (the gray line), RR + damping operators (DRR)(the blue line), DRR + MA operators (the black line) and DRR + STMA operators (RDRR)(the red line). From the S/N diagrams, we deduce that the proposed STMA operator can be used to greatly improve the conventional RR and the DRR methods. The comparison of each S/N diagram highlights the contribution of the proposed STMA operator in the RR and DRR methods.} 

\inputdir{synth_operators}
\multiplot{5}{synth-rrdamping-s,synth-rrstma-s,synth-rrdampingst-s,synth-rrdampingma-s,synth-rrdampingstma-s}{width=0.29\textwidth}{Common-offset 2D figures comparison after \wen{10}\dlo{wen} iterations. (a) The RR + damping operators (DRR method). (b) The RR + ST + MA operators. (c) The result of RR + damping + ST operators. (d) The result provided by the RR + damping + MA operators. (e) The result of the proposed approach (RR + damping + ST+ MA). We have tested these approaches on 5D synthetic data corrupted by 0.3 as the noise level and $70\%$ of missing traces.}

\inputdir{synth_operators}
\multiplot{5}{synth-rrdamping-xy-e-s,synth-rrstma-xy-e-s,synth-rrdampingst-xy-e-s,synth-rrdampingma-xy-e-s,synth-rrdampingstma-xy-e-s}{width=0.3\textwidth}{Common-offset 2D figures comparison after \wen{ten}\dlo{10} iterations. (a) The RR + damping operators (DRR method). (b) The RR + ST + MA operators. (c) The result of RR + damping + ST operators. (d) The result provided by the RR + damping + MA operators. (e) The result of the proposed approach (RR + damping + ST+ MA). We have tested these approaches on 5D synthetic data corrupted by 0.3 as the noise level and $70\%$ of missing traces.}

\inputdir{./}
\plot{Contribution_of_each_operator}{width=0.5\columnwidth}{Comparison of S/N\dlo{s} values as a function of ratio of missing traces between the RR (the yellow line), RR + MA (the green line), RR + STMA (the gray line), DRR (the blue line), DRR + MA (the black line), and DRR + STMA (the red line) under a noise variance of $0.3$ and $70\%$ as missing traces.}

\wen{The five key parameters \dlo{that use}\wen{in} the proposed approach are selected using the following strategy.} According to the Cadzow filtering method based on the linear event assumption, $K$ is defined as the number of different dip elements. \wen{In the condition of curved and complex events, $K$ should be approximately higher than the number of different dip components for producing more reliable results. The selection of $K$ generally influences substantially the performance of the RR-based methods. Indeed, the smaller values of $K$ will damage the signal, whereas higher values of $K$ will generate considerable noise in the result.} \dlo{Based on this assumption, we have conducted several tests to figure out the best results. The selection of $K$ influences substantially the performance of the proposed method. Indeed, the smaller value of $K$ will damage the signal whereas higher values of $K$ will generate considerable noise in the result. Because of the best quality of the signals obtained after applying the proposed method, it is better to choose rank $K$ = 6, for synthetic and field seismic data sets}\dlo{.}\wen{The damping factor can be selected in the interval \wen{of} $d\in[1,3]$}.\dlo{Concerning the damping factor,} \wen{In the case of data generally including linear events or no complex structures, $d = 1$ damages the useful signal. When $d = 3$, it produces some residual noise in the result. However, when we use $d = 2$, the results are perfect. Indeed, random noise can be greatly suppressed and the useful signal can be recovered for synthetic and field seismic data sets. However, when the data to be restored contains curved events or complex structures, $d = 3$ can be selected.} \dlo{When we use $d$ = 1, the proposed approach damages the useful signal. When $d$ = 3, it produces some residual noise in the result. However, when we use $d$ = 2, the results are \old{perfect}\new{better}. Indeed, random noise can be greatly suppressed and the useful signal can be recovered for synthetic and field seismic data sets}\dlo{.}\wen{Besides, the parameter $T$ should be a positive integer ($T>0$). It is important to know that when $T$ is too \dlo{long}\wen{larger}, it \dlo{creates}\wen{causes} some loss of useful signals (Figure \dlo{\ref{fig:28}}\wen{\ref{fig:synth-hxhy-s-stma2}\dlo{(b)}) even though the S/N can be improved. As a consequence, the amplitude of the signal can be seriously degraded. Moreover, if $T$ is \dlo{much short}\wen{too small} (Figure \ref{fig:synth-hxhy-s-stma1}), it cannot attenuate residual noise well.\dlo{(Figures \dlo{\ref{fig:30}(a and c)}\wen{\ref{fig:31}(a) and \ref{fig:31}(c)}).} However, the useful signal can be preserved. Therefore, in the proposed approach we should select a smaller value of $T$ to preserve the quality of the useful signal. To avoid \dlo{the signal damage}\wen{damaging signal}, we always select $T=1$ whatever the condition of noise and missing data and also the type (complex, linear or curved events) of the data to be reconstructed.
The parameters $e$ and $\beta$ should be selected considering \dlo{some information about}the noise level, the percentage of missing traces, and the iteration numbers used to run the proposed algorithm. In general, $e$ should be \old{greater than $0$ but less or equal to $1$}$ 0 < e \leq 1$. \wen{The larger value of $e$}\dlo{If the value of $e$ is much large, it} may produce redundant data and cause new noise\dlo{.}\wen{, and t}he energy of the signal may be seriously affected. In addition, if $e$ is extremely small, it may yield \dlo{over-smoothing results}\wen{an overly smooth result} and signal distortion. After conducting many numerical tests on different synthetic data, we realize that it is better to always set $e$ around $1$ ($e \leq 1$). From these tests, we can deduce significant conclusions about this useful parameter. When the percentage of missing data decreases, $e$ must be selected very close to $1$ ($ e \leq 1 $). In other words, we have to select $e$ by decreasing $1$ very slightly until achieving the best result. For instance, when the 5D synthetic data \old{is}\new{are} corrupted by a noise level of $0.3$ with $20\%$ of missing data, we choose $e = 0.997$. However, for the $90\%$ decimation, we need to select $e$ by gradually moving away from $1$. For example, using a noise level of $0.2$ with $90\%$ of missing traces, we choose $e = 0.891$. This meaningful indication about $e$ can also be applied in the case of field data. For instance, we used $e = 0.9$ when recovering the real field data of this paper, which missed approximately $75\%$ of traces. Under the same condition of noise and missing traces, we should increase gradually the value of $e$ when the iteration numbers increase. For example, $e$ can be set from $0.95, 0.97,..,$ to $1$ for iteration varying from $5, 10,.., $ to $40$ based on the same noise level and missing data. This is verified for any type of data to be recovered}}. 
To greatly impose sparsity into the level-4 block Hankel matrix \wen{after DTSVD}, we set the thresholding parameter $\tau$ as \dlo{the value}defined in the The RDRR Method section. From this approach, we use the cooling factor $\beta$ to adjust $\tau$. This useful tool helps to control the smoothing degree. According to our experience, it is better to select a small $\beta$ \wen{for data having linear events. All $\beta$ used for the synthetic data examples containing linear \wen{events} have been selected between values from \dlo{$2$}\wen{$2.0$} to $3.5$. In contrast, a relatively greater value of $\beta$ should be set for data that are composed of curved events. The values of $\beta$ have been selected from $5$ to $17$ for the different tests on curved data of this paper. As a general rule, when the percentage of missing traces, noise levels and iteration numbers decrease, a relatively larger value of $\beta$ should be selected.} Note that, \wen{if}\dlo{even though only} one parameter is not appropriately set, it may affect the simultaneous denoising and reconstruction performance. Thus, to reach the best trade-off between random noise \dlo{attenuating}\wen{attenuation} and useful signal preservation, we should choose the parameters properly.

\dlo{According to our experience, it is better to select a small $\beta$ around 3 in general for synthetic data. All $\beta$ used for the synthetic data examples have been selected between values from 2 to 3.5. A relatively small $\beta$ is also generally more adequate and suitable for field data. For the field data examples, we use $\beta$ = 3. Note that, when $\beta$ is very large, the smoothing damages the useful signal amplitude. Besides, when $T$ is too long, it creates some loss of useful signals. However, if $T$ is much short, it cannot attenuate residual noise well. Therefore, we always select $T$ = 1 for synthetic and field data to avoid the signal damage. On the other hand, \dlo{if the rational transfer coefficient $e$ is much large, it}\wen{larger values of $e$} may produce redundant data and cause new noise. Also, if $e$ is extremely small, it may yield over-smoothing results and signal distortion. After conducting many numerical tests on different synthetic data, we realize that it is better to set $e$ always to around 1. From these tests, we can deduce significant conclusions about this last parameter. When the percentage of missing data decreases, $e$ must be selected very close to 1. In other words, we have to select $e$ by decreasing 1 very slightly until achieving the best result. For instance, when the 5D synthetic data \dlo{is}\wen{are} corrupted by a noise level of $0.3$ with $20\%$ of missing data, we choose $e$ = 0.997. On the other hand, for the $90\%$ decimation, we need to select $e$ by gradually moving away from 1. For example, using a noise level of $0.2$ with $90\%$ of missing traces, we choose $e$ = 0.891. This meaningful indication about $e$ can also be applied in the case of field data. For instance, we use $e$ = 0.9 when recovering the real field data of this paper.}

Here, we focus our attention on the comparison of the visual examination and numerical tests. Compared with the DRR framework, the proposed method can successfully outperform in each \dlo{case aforementioned}\wen{aforementioned case}. \dlo{Indeed, t}\wen{T}he simultaneously denoised and reconstructed data from our approach are always better than those of the DRR method. As the noise level, the percentage of missing traces, and the number of iterations increase, the difference between both algorithms is still \dlo{impressive}\wen{evident}. Based on the lower rms error values of our method, we deduce that the proposed algorithm can yield better accuracy results than the DRR approach. The analysis of the numerical tests provides \dlo{a}useful and practical instruction that the RDRR method can be successfully used in the situation \dlo{. It may even contain}\wen{of} \dlo{stiff}\wen{strong} random noise and a high level of missing observation, which is often the characteristic of most seismic data acquired on land. According to the frequency analysis, our method can be used to enhance the resolution of seismic data because of its better ability to provide \dlo{high frequency}\wen{high-frequency components} compared to the DRR approach. 

\section{conclusions}
We have demonstrated the feasibility of a novel method for simultaneous denoising and reconstruction of 5D seismic data. Using the advantages of the damping operator and the proposed STMA operator, we have constructed a novel improved method based on a new RDRR formula. We introduce the proposed framework to accurately restore the useful signal and suppress the random noise left after the DRR method process. The proposed approach benefiting from multiple operators yields better results compared to the DRR method. We use different 5D synthetic and one 5D field seismic data sets corrupted by random noise to examine the accuracy of our algorithm. The results for simultaneous denoising and reconstruction are shown in terms of the visual examination and numerical tests. As demonstrated from the detailed analysis, our proposed framework behaves very well even in the situation of very high noise levels and high ratios of missing traces.

\section{acknowledgments}
We would like to thank three anonymous reviewers for constructive suggestions. The research is supported by the National Natural Science Foundation of China (grant no. 41804140) and the starting fund from Zhejiang University.

\section{Data and materials availability}
Data associated with this research are available and can be obtained by contacting the corresponding author.

\bibliographystyle{apalike}
\bibliography{rdrr}

